{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:53:18.211444Z","iopub.execute_input":"2025-09-13T19:53:18.211741Z","iopub.status.idle":"2025-09-13T19:53:18.216849Z","shell.execute_reply.started":"2025-09-13T19:53:18.211714Z","shell.execute_reply":"2025-09-13T19:53:18.216108Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install implicit scikit-surprise mlflow sentence-transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:53:18.218550Z","iopub.execute_input":"2025-09-13T19:53:18.218839Z","iopub.status.idle":"2025-09-13T19:55:00.400837Z","shell.execute_reply.started":"2025-09-13T19:53:18.218819Z","shell.execute_reply":"2025-09-13T19:55:00.399827Z"}},"outputs":[{"name":"stdout","text":"Collecting implicit\n  Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\nCollecting mlflow\n  Downloading mlflow-3.3.2-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.26.4)\nRequirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\nRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.5.1)\nCollecting mlflow-skinny==3.3.2 (from mlflow)\n  Downloading mlflow_skinny-3.3.2-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.3.2 (from mlflow)\n  Downloading mlflow_tracing-3.3.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.2)\nRequirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (44.0.3)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nCollecting graphene<4 (from mlflow)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.2)\nRequirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.3)\nRequirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.3.2->mlflow)\n  Downloading databricks_sdk-0.65.0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.115.13)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.7.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.3.2->mlflow)\n  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.3.2->mlflow)\n  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.34.3)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<46,>=43.0.0->mlflow) (1.17.1)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow) (2.22)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (2.40.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow) (3.23.0)\nCollecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow)\n  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (2025.6.15)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.3.2->mlflow) (0.16.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->implicit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->implicit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->implicit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->implicit) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (4.9.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->implicit) (2024.2.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.6.1)\nDownloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow-3.3.2-py3-none-any.whl (26.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mlflow_skinny-3.3.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading mlflow_tracing-3.3.2-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.65.0-py3-none-any.whl (705 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.9/705.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gunicorn, graphql-core, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, graphql-relay, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, graphene, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow, implicit\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed databricks-sdk-0.65.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 implicit-0.7.2 mlflow-3.3.2 mlflow-skinny-3.3.2 mlflow-tracing-3.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opentelemetry-api-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==============================\n# 1. Imports & Config\n# ==============================\nimport pandas as pd\nimport numpy as np\nimport json\nfrom scipy.sparse import coo_matrix\nfrom implicit.als import AlternatingLeastSquares\nfrom sentence_transformers import SentenceTransformer, util\nimport mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:55:00.402009Z","iopub.execute_input":"2025-09-13T19:55:00.402287Z","iopub.status.idle":"2025-09-13T19:55:31.242802Z","shell.execute_reply.started":"2025-09-13T19:55:00.402260Z","shell.execute_reply":"2025-09-13T19:55:31.241678Z"}},"outputs":[{"name":"stderr","text":"2025-09-13 19:55:12.110221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757793312.315015      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757793312.373029      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ==============================\n# 2. Load Dataset (from Hugging Face)\n# ==============================\n!pip install datasets --quiet\n\nfrom datasets import load_dataset\n\n# Stream instead of full load\n# Add trust_remote_code=True to the function call\ndataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", split=\"full\", streaming=True, trust_remote_code=True)\n\n# Take first 500k rows into pandas\nreviews = dataset.take(500_000)\nimport pandas as pd\nreviews = pd.DataFrame(reviews)\n\nprint(\"Loaded:\", reviews.shape)\nprint(reviews.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:55:31.243840Z","iopub.execute_input":"2025-09-13T19:55:31.244526Z","iopub.status.idle":"2025-09-13T19:55:52.828842Z","shell.execute_reply.started":"2025-09-13T19:55:31.244500Z","shell.execute_reply":"2025-09-13T19:55:52.827880Z"}},"outputs":[{"name":"stdout","text":"Loaded: (500000, 10)\n   rating                                        title  \\\n0     3.0            Smells like gasoline! Going back!   \n1     1.0      Didn’t work at all lenses loose/broken.   \n2     5.0                                   Excellent!   \n3     5.0                       Great laptop backpack!   \n4     5.0  Best Headphones in the Fifties price range!   \n\n                                                text  \\\n0  First & most offensive: they reek of gasoline ...   \n1  These didn’t work. Idk if they were damaged in...   \n2  I love these. They even come with a carry case...   \n3  I was searching for a sturdy backpack for scho...   \n4  I've bought these headphones three times becau...   \n\n                                              images        asin parent_asin  \\\n0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n1                                                 []  B07N69T6TM  B07N69T6TM   \n2                                                 []  B01G8JO5F2  B01G8JO5F2   \n3                                                 []  B001OC5JKY  B001OC5JKY   \n4                                                 []  B013J7WUGC  B07CJYMRWM   \n\n                        user_id      timestamp  helpful_vote  \\\n0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1658185117948             0   \n1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1592678549731             0   \n2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1523093017534             0   \n3  AGGZ357AO26RQZVRLGU4D4N52DZQ  1290278495000            18   \n4  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1676601581238             0   \n\n   verified_purchase  \n0               True  \n1               True  \n2               True  \n3               True  \n4               True  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==============================\n# 3. Preprocessing (Robust version)\n# ==============================\n\n# Standardize column names\nreviews.rename(columns={\n    \"user_id\": \"reviewerID\",\n    \"asin\": \"asin\",\n    \"rating\": \"overall\",\n    \"text\": \"reviewText\",\n    \"timestamp\": \"unixReviewTime\"\n}, inplace=True)\n\n# Drop missing reviews/ratings\nreviews.dropna(subset=[\"reviewText\", \"overall\"], inplace=True)\nreviews.drop_duplicates(subset=[\"reviewerID\", \"asin\"], inplace=True)\n\n# Step 1: Filter active users/items BEFORE sampling\nuser_counts = reviews[\"reviewerID\"].value_counts()\nitem_counts = reviews[\"asin\"].value_counts()\n\nreviews = reviews[reviews[\"reviewerID\"].isin(user_counts[user_counts >= 5].index)]\nreviews = reviews[reviews[\"asin\"].isin(item_counts[item_counts >= 5].index)]\n\n# Step 2: Now sample (if still too large)\nmax_samples = 200000\nif len(reviews) > max_samples:\n    reviews = reviews.sample(max_samples, random_state=42)\n\nprint(\"Final dataset size:\", reviews.shape)\nprint(reviews.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:55:52.829929Z","iopub.execute_input":"2025-09-13T19:55:52.830327Z","iopub.status.idle":"2025-09-13T19:55:54.679489Z","shell.execute_reply.started":"2025-09-13T19:55:52.830299Z","shell.execute_reply":"2025-09-13T19:55:54.678386Z"}},"outputs":[{"name":"stdout","text":"Final dataset size: (166416, 10)\n    overall                                              title  \\\n5       5.0                              Great Fan! I’m a FAN!   \n6       5.0                          solid sound for the price   \n8       5.0                                         Five Stars   \n9       5.0                                     BUY THIS THANG   \n10      1.0  Not sure why this has good reviews. My devices...   \n\n                                           reviewText images        asin  \\\n5   Light weight, quiet and totally awesome!!! It ...     []  B072DSHKCH   \n6   Update 2-they sent a new warranty replacement....     []  B07BHHB5RH   \n8                          pretty good for the price.     []  B002HWRZ2K   \n9   yes.. so good.  just buy it. my favorite featu...     []  B00WK47VEW   \n10  This devices brought my wifi network to its kn...     []  B00L0YLRUW   \n\n   parent_asin                    reviewerID  unixReviewTime  helpful_vote  \\\n5   B07CML419K  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1637522881041             0   \n6   B07BHHB5RH  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1565130879386             0   \n8   B01LW71IBJ  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1456772571000             0   \n9   B017T99JPG  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1456772365000             0   \n10  B00L0YLRUW  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1439226089000             0   \n\n    verified_purchase  \n5                True  \n6                True  \n8                True  \n9                True  \n10               True  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==============================\n# 4. Collaborative Filtering (ALS)\n# ==============================\nuser_map = {u:i for i,u in enumerate(reviews[\"reviewerID\"].unique())}\nitem_map = {p:i for i,p in enumerate(reviews[\"asin\"].unique())}\n\n\nrows = reviews[\"reviewerID\"].map(user_map)\ncols = reviews[\"asin\"].map(item_map)\nvals = reviews[\"overall\"]\n\nfrom scipy.sparse import coo_matrix\n\n# Construct the COO matrix\nmatrix = coo_matrix((vals, (rows, cols)))\n\n# Convert to CSR for efficient row slicing\nmatrix_csr = matrix.tocsr()\n\n\nals = AlternatingLeastSquares(factors=64, regularization=0.1, iterations=15)\nals.fit(matrix.T)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:55:54.680393Z","iopub.execute_input":"2025-09-13T19:55:54.680655Z","iopub.status.idle":"2025-09-13T19:55:57.721786Z","shell.execute_reply.started":"2025-09-13T19:55:54.680633Z","shell.execute_reply":"2025-09-13T19:55:57.720718Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 2 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n  check_blas_config()\n/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n  check_blas_config()\n/usr/local/lib/python3.11/dist-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0027594566345214844 seconds\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a9a716aa2374f6ab40129746ab24263"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# ==============================\n# 5. Content-Based Filtering (Sentence Transformers)\n# ==============================\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n\nproduct_texts = reviews.groupby(\"asin\")[\"reviewText\"].apply(lambda x: \" \".join(x[:5]))\n\n\nembeddings = model.encode(product_texts.tolist(), convert_to_tensor=True)\nproduct_index_map = {i: pid for i, pid in enumerate(product_texts.index)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T19:55:57.722776Z","iopub.execute_input":"2025-09-13T19:55:57.723080Z","iopub.status.idle":"2025-09-13T20:09:25.562739Z","shell.execute_reply.started":"2025-09-13T19:55:57.723054Z","shell.execute_reply":"2025-09-13T20:09:25.560335Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166779b1d3f84ad38dee8998ee452b53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5669a8d7d8a435cab43358d30524428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27897bd83d6f4f29936803356c7814cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a159b8e5983646aabac0424173c4cee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2fc34c1364a4a189274cebf49f1cdfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600c702916e24ddcacb4085982f32aea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b0e8ebfb4a48e99ee4b7fcde31c22e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820a43f079874b71a20596c0881e64fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d1457963b840769f8430042292b4c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e676e18a00404c5096a72fc62025290b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbe832403604bd9a2330fe2b683f740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/534 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c75b9d2c00448e1a7f14f90fa0555d8"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# ==============================\n# 6. Hybrid Recommendation Function\n# ==============================\ndef hybrid_recommend(user_id, topn=10, alpha=0.6):\n    if user_id not in user_map:\n        return []\n\n    # CF recommendations\n    item_indices, scores = als.recommend(user_map[user_id], matrix_csr[user_map[user_id]], N=topn * 2)\n\n    hybrid_results = []\n    \n    # Create a reverse map for faster lookups\n    index_product_map = {v: k for k, v in item_map.items()}\n\n    for item_id, score in zip(item_indices, scores):\n        # Check if item_id is a valid key in the content-based map\n        if item_id in product_index_map:\n            # content similarity with candidate item\n            sim_scores = util.cos_sim(embeddings[item_id], embeddings)[0].cpu().numpy()\n            content_score = np.mean(sim_scores)\n            \n            # weighted combination\n            final_score = alpha * score + (1 - alpha) * content_score\n            hybrid_results.append((product_index_map[item_id], final_score))\n        else:\n            # The item does not have a content-based representation, so use the CF score\n            # It's better to use the original asin from the full item map\n            original_asin = index_product_map.get(item_id, None)\n            if original_asin:\n                hybrid_results.append((original_asin, alpha * score))\n            \n    # Sort by final score and keep top N\n    hybrid_results = sorted(hybrid_results, key=lambda x: -x[1])[:topn]\n    \n    return [asin for asin, _ in hybrid_results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T20:09:25.570436Z","iopub.execute_input":"2025-09-13T20:09:25.571177Z","iopub.status.idle":"2025-09-13T20:09:25.583518Z","shell.execute_reply.started":"2025-09-13T20:09:25.571094Z","shell.execute_reply":"2025-09-13T20:09:25.582486Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ==============================\n# 7. Example Run\n# ==============================\nexample_user = reviews[\"reviewerID\"].iloc[0]\nprint(\"Recommendations for:\", example_user)\nprint(hybrid_recommend(example_user, topn=5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T20:09:25.584632Z","iopub.execute_input":"2025-09-13T20:09:25.585001Z","iopub.status.idle":"2025-09-13T20:09:25.676291Z","shell.execute_reply.started":"2025-09-13T20:09:25.584971Z","shell.execute_reply":"2025-09-13T20:09:25.675337Z"}},"outputs":[{"name":"stdout","text":"Recommendations for: AGCI7FAH4GL5FI65HYLKWTMFZ2CQ\n['B00GFAN498', 'B07YF3PZ7Z', 'B00EL94Z4I', 'B004KM82IQ', 'B001FO4QHI']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ==============================\n# 8. Evaluation Metrics (Precision@K, Recall@K)\n# ==============================\ndef precision_recall_at_k(user_ids, k=10):\n    precisions, recalls = [], []\n    num_users = len(als.user_factors)\n    \n    for uid in user_ids:\n        # Get the numerical user index from the map\n        user_idx = user_map.get(uid)\n        \n        # Check if user is in map and if the index is valid for the ALS model\n        if user_idx is None or user_idx >= num_users:\n            continue\n\n        true_items = set(reviews[reviews[\"reviewerID\"] == uid][\"asin\"])\n        recommended = set(hybrid_recommend(uid, topn=k))\n        \n        if not true_items:\n            continue\n            \n        hits = len(true_items & recommended)\n        precisions.append(hits / k)\n        recalls.append(hits / len(true_items))\n    return np.mean(precisions), np.mean(recalls)\n\n# Sample users from the filtered list of users (keys of user_map)\nsample_users = pd.Series(list(user_map.keys())).sample(100)\nprecision, recall = precision_recall_at_k(sample_users, k=10)\nprint(\"Precision@10:\", precision)\nprint(\"Recall@10:\", recall)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T20:09:25.677338Z","iopub.execute_input":"2025-09-13T20:09:25.677867Z","iopub.status.idle":"2025-09-13T20:09:32.859193Z","shell.execute_reply.started":"2025-09-13T20:09:25.677843Z","shell.execute_reply":"2025-09-13T20:09:32.858264Z"}},"outputs":[{"name":"stdout","text":"Precision@10: 0.0\nRecall@10: 0.0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\n\n# ==============================\n# 9. MLOps Hooks (MLflow)\n# ==============================\nwith mlflow.start_run():\n    mlflow.log_param(\"ALS_factors\", 64)\n    mlflow.log_param(\"Embedding_model\", \"all-MiniLM-L6-v2\")\n    mlflow.log_metric(\"Precision_at_10\", precision)\n    mlflow.log_metric(\"Recall_at_10\", recall)\n    \n    # Create a dummy input example for a single user ID\n    user_id_example = np.array([0])\n    \n    # Use 'name' instead of 'artifact_path' and provide an input_example\n    mlflow.sklearn.log_model(\n        sk_model=als,\n        name=\"ALS_model\",\n        input_example=user_id_example,\n        # The ALS model from the implicit library is not a scikit-learn model,\n        # so we must explicitly specify the flavor to avoid logging it as such.\n        # Here we'll just use the generic python_model flavor.\n        # This will still log the model but without the scikit-learn specific functionality.\n        # You may need to create a custom wrapper for proper serving.\n        # However, for the purpose of this notebook, this is sufficient.\n        serialization_format=\"pickle\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T20:09:32.860125Z","iopub.execute_input":"2025-09-13T20:09:32.860398Z","iopub.status.idle":"2025-09-13T20:09:46.764507Z","shell.execute_reply.started":"2025-09-13T20:09:32.860369Z","shell.execute_reply":"2025-09-13T20:09:46.763477Z"}},"outputs":[{"name":"stderr","text":"2025/09/13 20:09:33 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: AttributeError(\"'AlternatingLeastSquares' object has no attribute 'predict'\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n2025/09/13 20:09:33 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n2025/09/13 20:09:46 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"inputs\": [\n    0\n  ]\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Model does not have the \"python_function\" flavor\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hybrid_recommend(user_id, topn=10, alpha=0.6):\n    if user_id not in user_map:\n        return list(product_index_map.values())[:topn]  # fallback popular items\n\n    user_idx = user_map[user_id]\n\n    if user_idx >= als.user_factors.shape[0]:\n        return list(product_index_map.values())[:topn]\n\n    item_indices, scores = als.recommend(user_idx, matrix_csr[user_idx], N=topn*2)\n\n    hybrid_results = []\n    for item_idx, cf_score in zip(item_indices, scores):\n        # Skip if item index is out of range\n        if item_idx >= embeddings.shape[0]:\n            content_score = 0\n        else:\n            sim_scores = util.cos_sim(embeddings[item_idx], embeddings)[0].cpu().numpy()\n            content_score = np.mean(sim_scores)\n\n        final_score = alpha * cf_score + (1 - alpha) * content_score\n        hybrid_results.append((item_idx, final_score))\n\n    # Sort and take top N\n    hybrid_results = sorted(hybrid_results, key=lambda x: -x[1])[:topn]\n\n    # Filter out invalid indices\n    recommended_asins = [\n        product_index_map.get(i, None) for i, _ in hybrid_results if i in product_index_map\n    ]\n\n    return recommended_asins\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:01:37.796300Z","iopub.execute_input":"2025-09-13T21:01:37.796674Z","iopub.status.idle":"2025-09-13T21:01:37.805346Z","shell.execute_reply.started":"2025-09-13T21:01:37.796642Z","shell.execute_reply":"2025-09-13T21:01:37.804400Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ==============================\n# 8. Evaluation Metrics (Precision@K, Recall@K)\n# ==============================\ndef precision_recall_at_k(user_ids, k=10):\n    precisions, recalls = [], []\n    num_users = len(als.user_factors)\n    \n    for uid in user_ids:\n        # Get the numerical user index from the map\n        user_idx = user_map.get(uid)\n        \n        # Check if user is in map and if the index is valid for the ALS model\n        if user_idx is None or user_idx >= num_users:\n            continue\n\n        true_items = set(reviews[reviews[\"reviewerID\"] == uid][\"asin\"])\n        recommended = set(hybrid_recommend(uid, topn=k))\n        \n        if not true_items:\n            continue\n            \n        hits = len(true_items & recommended)\n        precisions.append(hits / k)\n        recalls.append(hits / len(true_items))\n    return np.mean(precisions), np.mean(recalls)\n\n# Sample users from the filtered list of users (keys of user_map)\nsample_users = pd.Series(list(user_map.keys())).sample(100)\nprecision, recall = precision_recall_at_k(sample_users, k=10)\nprint(\"Precision@10:\", precision)\nprint(\"Recall@10:\", recall)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:01:39.650972Z","iopub.execute_input":"2025-09-13T21:01:39.651290Z","iopub.status.idle":"2025-09-13T21:01:46.442051Z","shell.execute_reply.started":"2025-09-13T21:01:39.651267Z","shell.execute_reply":"2025-09-13T21:01:46.441176Z"}},"outputs":[{"name":"stdout","text":"Precision@10: 0.0\nRecall@10: 0.0\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#1️⃣ Data Sampling + Train-Test Spli\n# ==============================\n# 2. Load Dataset (from Hugging Face)\n# ==============================\n!pip install datasets --quiet\n\nfrom datasets import load_dataset\nimport pandas as pd\n\n# Stream instead of full load\ndataset = load_dataset(\n    \"McAuley-Lab/Amazon-Reviews-2023\",\n    \"raw_review_Electronics\",\n    split=\"full\",\n    streaming=True,\n    trust_remote_code=True\n)\n\n# Take first 500k rows into pandas\nreviews = pd.DataFrame(dataset.take(500_000))\n\nprint(\"Loaded reviews shape:\", reviews.shape)\nprint(reviews.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:05:09.105299Z","iopub.execute_input":"2025-09-13T21:05:09.105651Z","iopub.status.idle":"2025-09-13T21:05:32.478646Z","shell.execute_reply.started":"2025-09-13T21:05:09.105600Z","shell.execute_reply":"2025-09-13T21:05:32.477661Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Loaded reviews shape: (500000, 10)\n   rating                                        title  \\\n0     3.0            Smells like gasoline! Going back!   \n1     1.0      Didn’t work at all lenses loose/broken.   \n2     5.0                                   Excellent!   \n3     5.0                       Great laptop backpack!   \n4     5.0  Best Headphones in the Fifties price range!   \n\n                                                text  \\\n0  First & most offensive: they reek of gasoline ...   \n1  These didn’t work. Idk if they were damaged in...   \n2  I love these. They even come with a carry case...   \n3  I was searching for a sturdy backpack for scho...   \n4  I've bought these headphones three times becau...   \n\n                                              images        asin parent_asin  \\\n0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n1                                                 []  B07N69T6TM  B07N69T6TM   \n2                                                 []  B01G8JO5F2  B01G8JO5F2   \n3                                                 []  B001OC5JKY  B001OC5JKY   \n4                                                 []  B013J7WUGC  B07CJYMRWM   \n\n                        user_id      timestamp  helpful_vote  \\\n0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1658185117948             0   \n1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1592678549731             0   \n2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1523093017534             0   \n3  AGGZ357AO26RQZVRLGU4D4N52DZQ  1290278495000            18   \n4  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1676601581238             0   \n\n   verified_purchase  \n0               True  \n1               True  \n2               True  \n3               True  \n4               True  \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# ==============================\n# 3. Preprocessing (Without Category Mapping)\n# ==============================\n\n# Standardize column names\nreviews.rename(columns={\n    \"user_id\": \"reviewerID\",\n    \"asin\": \"asin\",\n    \"rating\": \"overall\",\n    \"text\": \"reviewText\",\n    \"timestamp\": \"unixReviewTime\"\n}, inplace=True)\n\n# Drop missing values and duplicates\nreviews.dropna(subset=[\"reviewText\", \"overall\"], inplace=True)\nreviews.drop_duplicates(subset=[\"reviewerID\", \"asin\"], inplace=True)\n\n# Filter active users/items BEFORE sampling\nuser_counts = reviews[\"reviewerID\"].value_counts()\nitem_counts = reviews[\"asin\"].value_counts()\n\nreviews = reviews[reviews[\"reviewerID\"].isin(user_counts[user_counts >= 2].index)]\nreviews = reviews[reviews[\"asin\"].isin(item_counts[item_counts >= 2].index)]\n\nprint(\"Filtered dataset size:\", reviews.shape)\nprint(reviews.head())\n\n# Train-test split (80-20)\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(reviews, test_size=0.2, random_state=42)\n\n# Build ground truth mapping for evaluation\nground_truth = test_df.groupby('reviewerID')['asin'].apply(set).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:05:32.480235Z","iopub.execute_input":"2025-09-13T21:05:32.480512Z","iopub.status.idle":"2025-09-13T21:05:36.216014Z","shell.execute_reply.started":"2025-09-13T21:05:32.480490Z","shell.execute_reply":"2025-09-13T21:05:36.215103Z"}},"outputs":[{"name":"stdout","text":"Filtered dataset size: (338895, 10)\n   overall                                    title  \\\n0      3.0        Smells like gasoline! Going back!   \n1      1.0  Didn’t work at all lenses loose/broken.   \n2      5.0                               Excellent!   \n5      5.0                    Great Fan! I’m a FAN!   \n6      5.0                solid sound for the price   \n\n                                          reviewText  \\\n0  First & most offensive: they reek of gasoline ...   \n1  These didn’t work. Idk if they were damaged in...   \n2  I love these. They even come with a carry case...   \n5  Light weight, quiet and totally awesome!!! It ...   \n6  Update 2-they sent a new warranty replacement....   \n\n                                              images        asin parent_asin  \\\n0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n1                                                 []  B07N69T6TM  B07N69T6TM   \n2                                                 []  B01G8JO5F2  B01G8JO5F2   \n5                                                 []  B072DSHKCH  B07CML419K   \n6                                                 []  B07BHHB5RH  B07BHHB5RH   \n\n                     reviewerID  unixReviewTime  helpful_vote  \\\n0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   1658185117948             0   \n1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   1592678549731             0   \n2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ   1523093017534             0   \n5  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1637522881041             0   \n6  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ   1565130879386             0   \n\n   verified_purchase  \n0               True  \n1               True  \n2               True  \n5               True  \n6               True  \n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#2️⃣ Robust Hybrid Recommendation Function\ndef hybrid_recommend(user_id, topn=10, alpha=0.6):\n    if user_id not in user_map:\n        # Cold-start fallback: return most popular products\n        return list(product_index_map.values())[:topn]\n    \n    user_idx = user_map[user_id]\n    if user_idx >= als.user_factors.shape[0]:\n        return list(product_index_map.values())[:topn]\n\n    item_indices, scores = als.recommend(user_idx, matrix_csr[user_idx], N=topn * 2)\n    hybrid_results = []\n\n    for item_idx, cf_score in zip(item_indices, scores):\n        if item_idx >= embeddings.shape[0]:\n            content_score = 0\n        else:\n            sim_scores = util.cos_sim(embeddings[item_idx], embeddings)[0].cpu().numpy()\n            content_score = np.max(sim_scores)  # Fixed from mean to max\n\n        final_score = alpha * cf_score + (1 - alpha) * content_score\n        hybrid_results.append((item_idx, final_score))\n\n    hybrid_results = sorted(hybrid_results, key=lambda x: -x[1])[:topn]\n\n    recommended_asins = [\n        product_index_map.get(i, None) for i, _ in hybrid_results if i in product_index_map\n    ]\n\n    return recommended_asins\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:05:36.217064Z","iopub.execute_input":"2025-09-13T21:05:36.217399Z","iopub.status.idle":"2025-09-13T21:05:36.226640Z","shell.execute_reply.started":"2025-09-13T21:05:36.217369Z","shell.execute_reply":"2025-09-13T21:05:36.225587Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#3️⃣ Evaluation + MLflow Logging\nimport mlflow\n\nsample_users = random.sample(list(ground_truth.keys()), min(1000, len(ground_truth)))\ntop_k = 10\nprecisions = []\nrecalls = []\n\nfor user_id in sample_users:\n    recommended_items = set(hybrid_recommend(user_id, topn=top_k, alpha=0.6))\n    true_items = ground_truth[user_id]\n\n    if not true_items:\n        continue\n\n    hits = len(recommended_items & true_items)\n    precision = hits / top_k\n    recall = hits / len(true_items)\n\n    precisions.append(precision)\n    recalls.append(recall)\n\navg_precision = sum(precisions) / len(precisions)\navg_recall = sum(recalls) / len(recalls)\n\nprint(f\"Precision@{top_k}: {avg_precision:.4f}\")\nprint(f\"Recall@{top_k}: {avg_recall:.4f}\")\n\n# Log to MLflow\nwith mlflow.start_run():\n    mlflow.log_param(\"top_k\", top_k)\n    mlflow.log_metric(f\"precision_at_{top_k}\", avg_precision)\n    mlflow.log_metric(f\"recall_at_{top_k}\", avg_recall)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:05:36.228408Z","iopub.execute_input":"2025-09-13T21:05:36.228709Z","iopub.status.idle":"2025-09-13T21:06:10.749571Z","shell.execute_reply.started":"2025-09-13T21:05:36.228688Z","shell.execute_reply":"2025-09-13T21:06:10.748592Z"}},"outputs":[{"name":"stdout","text":"Precision@10: 0.0001\nRecall@10: 0.0002\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*First Draft*","metadata":{}},{"cell_type":"code","source":"!pip install datasets implicit scikit-surprise mlflow sentence-transformers --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:10:51.420699Z","iopub.execute_input":"2025-09-13T21:10:51.421183Z","iopub.status.idle":"2025-09-13T21:10:56.459290Z","shell.execute_reply.started":"2025-09-13T21:10:51.421156Z","shell.execute_reply":"2025-09-13T21:10:56.458071Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\n# Stream and sample first 500k rows\ndataset = load_dataset(\n    \"McAuley-Lab/Amazon-Reviews-2023\",\n    \"raw_review_Electronics\",\n    split=\"full\",\n    streaming=True,\n    trust_remote_code=True\n)\n\nreviews = pd.DataFrame(dataset.take(500_000))\nprint(\"Initial loaded shape:\", reviews.shape)\nprint(reviews.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:10:58.756149Z","iopub.execute_input":"2025-09-13T21:10:58.756523Z","iopub.status.idle":"2025-09-13T21:11:15.724445Z","shell.execute_reply.started":"2025-09-13T21:10:58.756491Z","shell.execute_reply":"2025-09-13T21:11:15.723488Z"}},"outputs":[{"name":"stdout","text":"Initial loaded shape: (500000, 10)\n   rating                                        title  \\\n0     3.0            Smells like gasoline! Going back!   \n1     1.0      Didn’t work at all lenses loose/broken.   \n2     5.0                                   Excellent!   \n3     5.0                       Great laptop backpack!   \n4     5.0  Best Headphones in the Fifties price range!   \n\n                                                text  \\\n0  First & most offensive: they reek of gasoline ...   \n1  These didn’t work. Idk if they were damaged in...   \n2  I love these. They even come with a carry case...   \n3  I was searching for a sturdy backpack for scho...   \n4  I've bought these headphones three times becau...   \n\n                                              images        asin parent_asin  \\\n0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n1                                                 []  B07N69T6TM  B07N69T6TM   \n2                                                 []  B01G8JO5F2  B01G8JO5F2   \n3                                                 []  B001OC5JKY  B001OC5JKY   \n4                                                 []  B013J7WUGC  B07CJYMRWM   \n\n                        user_id      timestamp  helpful_vote  \\\n0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1658185117948             0   \n1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1592678549731             0   \n2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1523093017534             0   \n3  AGGZ357AO26RQZVRLGU4D4N52DZQ  1290278495000            18   \n4  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1676601581238             0   \n\n   verified_purchase  \n0               True  \n1               True  \n2               True  \n3               True  \n4               True  \n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Rename columns\nreviews.rename(columns={\n    \"user_id\": \"reviewerID\",\n    \"asin\": \"asin\",\n    \"rating\": \"overall\",\n    \"text\": \"reviewText\",\n    \"timestamp\": \"unixReviewTime\"\n}, inplace=True)\n\n# Drop missing and duplicate entries\nreviews.dropna(subset=[\"reviewText\", \"overall\"], inplace=True)\nreviews.drop_duplicates(subset=[\"reviewerID\", \"asin\"], inplace=True)\n\n# Filter active users/items\nuser_counts = reviews[\"reviewerID\"].value_counts()\nitem_counts = reviews[\"asin\"].value_counts()\n\nreviews = reviews[reviews[\"reviewerID\"].isin(user_counts[user_counts >= 2].index)]\nreviews = reviews[reviews[\"asin\"].isin(item_counts[item_counts >= 2].index)]\n\nprint(\"Filtered dataset size:\", reviews.shape)\n\n# Train-test split\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(reviews, test_size=0.2, random_state=42)\n\n# Ground truth for evaluation\nground_truth = test_df.groupby('reviewerID')['asin'].apply(set).to_dict()\n\nprint(f\"Train size: {train_df.shape}, Test size: {test_df.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:11:15.725805Z","iopub.execute_input":"2025-09-13T21:11:15.726084Z","iopub.status.idle":"2025-09-13T21:11:20.284843Z","shell.execute_reply.started":"2025-09-13T21:11:15.726056Z","shell.execute_reply":"2025-09-13T21:11:20.283997Z"}},"outputs":[{"name":"stdout","text":"Filtered dataset size: (338895, 10)\nTrain size: (271116, 10), Test size: (67779, 10)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"#4️⃣ Build Interaction Matrix + Train ALS\nfrom implicit.als import AlternatingLeastSquares\nfrom scipy.sparse import coo_matrix\n\n# Mapping\nuser_ids = train_df['reviewerID'].unique().tolist()\nitem_ids = train_df['asin'].unique().tolist()\nuser_map = {uid: idx for idx, uid in enumerate(user_ids)}\nitem_map = {pid: idx for idx, pid in enumerate(item_ids)}\nproduct_index_map = {idx: pid for idx, pid in enumerate(item_ids)}\n\n# Build interaction matrix\nrows = train_df['reviewerID'].map(user_map)\ncols = train_df['asin'].map(item_map)\nvals = train_df['overall']\n\nmatrix = coo_matrix((vals, (rows, cols)))\nmatrix_csr = matrix.tocsr()\n\n# Train ALS\nals = AlternatingLeastSquares(factors=128, regularization=0.1, iterations=50)\nals.fit(matrix_csr.T)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:11:21.925730Z","iopub.execute_input":"2025-09-13T21:11:21.927111Z","iopub.status.idle":"2025-09-13T21:12:03.266344Z","shell.execute_reply.started":"2025-09-13T21:11:21.927075Z","shell.execute_reply":"2025-09-13T21:12:03.265368Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.008716583251953125 seconds\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee3f8740acd34f0fae350c7130e251e7"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"#5️⃣ Generate Product Embeddings (Content-Based)\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\nsemantic_model = SentenceTransformer('all-mpnet-base-v2')\n\n# Concatenate title + reviewText\nproduct_texts = train_df.groupby('asin')['reviewText'].apply(lambda x: ' '.join(x)).tolist()\nproduct_asins = train_df['asin'].unique().tolist()\nembeddings = semantic_model.encode(product_texts, convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T21:12:03.267997Z","iopub.execute_input":"2025-09-13T21:12:03.268342Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b552c50547b4639b8181beabe892798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4f7f1970de432daf73d6e998b8964a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d5853a5aa34b64b0595c88cac7adde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01c4b6f254424e9ea69fdcefc8d7f5ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d40ad77687754c6898e7058c6ec0f22c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2d6b3698be46b2a893e4eca0bd542a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8da564512714bca8ca6a6694096b5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c96e093bc54d8c856683f95a688ca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b28f876eb2402394e7d6d0cf57de58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0d4b0fc60d94b2d8eec1f371a32e3cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"849bb38038504518a57bd8f648235612"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2082 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407c90a7d1ab4e1193196772bc319f19"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#6️⃣ Semantic Search Function\ndef semantic_search(query, top_k=10):\n    query_embedding = semantic_model.encode([query], convert_to_tensor=True)\n    cos_scores = util.cos_sim(query_embedding, embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n    return [product_asins[idx] for idx in top_results.indices.cpu().numpy()]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#7️⃣ Hybrid Recommendation Function\ndef hybrid_recommend(user_id, topn=10, alpha=0.6):\n    if user_id not in user_map:\n        return product_asins[:topn]\n    \n    user_idx = user_map[user_id]\n    if user_idx >= als.user_factors.shape[0]:\n        return product_asins[:topn]\n\n    item_indices, scores = als.recommend(user_idx, matrix_csr[user_idx], N=topn * 2)\n    hybrid_results = []\n\n    for item_idx, cf_score in zip(item_indices, scores):\n        if item_idx >= embeddings.shape[0]:\n            content_score = 0\n        else:\n            sim_scores = util.cos_sim(embeddings[item_idx], embeddings)[0].cpu().numpy()\n            content_score = np.max(sim_scores)\n\n        final_score = alpha * cf_score + (1 - alpha) * content_score\n        hybrid_results.append((item_idx, final_score))\n\n    hybrid_results = sorted(hybrid_results, key=lambda x: -x[1])[:topn]\n\n    return [\n        product_index_map.get(i, None) for i, _ in hybrid_results if i in product_index_map\n    ]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#8️⃣ Evaluation + MLflow Logging\nimport mlflow\nimport random\n\nsample_users = random.sample(list(ground_truth.keys()), min(1000, len(ground_truth)))\ntop_k = 10\nprecisions = []\nrecalls = []\n\nfor user_id in sample_users:\n    recommended_items = set(hybrid_recommend(user_id, topn=top_k, alpha=0.6))\n    true_items = ground_truth[user_id]\n\n    if not true_items:\n        continue\n\n    hits = len(recommended_items & true_items)\n    precision = hits / top_k\n    recall = hits / len(true_items)\n\n    precisions.append(precision)\n    recalls.append(recall)\n\navg_precision = sum(precisions) / len(precisions)\navg_recall = sum(recalls) / len(recalls)\n\nprint(f\"Precision@{top_k}: {avg_precision:.4f}\")\nprint(f\"Recall@{top_k}: {avg_recall:.4f}\")\n\nwith mlflow.start_run():\n    mlflow.log_param(\"top_k\", top_k)\n    mlflow.log_param(\"alpha\", 0.6)\n    mlflow.log_metric(f\"precision_at_{top_k}\", avg_precision)\n    mlflow.log_metric(f\"recall_at_{top_k}\", avg_recall)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}