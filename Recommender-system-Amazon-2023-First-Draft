{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:31:46.347877Z","iopub.execute_input":"2025-09-14T18:31:46.348135Z","iopub.status.idle":"2025-09-14T18:31:48.276189Z","shell.execute_reply.started":"2025-09-14T18:31:46.348106Z","shell.execute_reply":"2025-09-14T18:31:48.275411Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"*First Draft*","metadata":{}},{"cell_type":"code","source":"!pip install datasets implicit scikit-surprise mlflow sentence-transformers --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:31:48.277859Z","iopub.execute_input":"2025-09-14T18:31:48.278179Z","iopub.status.idle":"2025-09-14T18:33:14.585287Z","shell.execute_reply.started":"2025-09-14T18:31:48.278161Z","shell.execute_reply":"2025-09-14T18:33:14.584550Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.9/705.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\n# Stream and sample first 500k rows\ndataset = load_dataset(\n    \"McAuley-Lab/Amazon-Reviews-2023\",\n    \"raw_review_Electronics\",\n    split=\"full\",\n    streaming=True,\n    trust_remote_code=True\n)\nreviews = pd.DataFrame(dataset.take(1_000_000))\n\n#reviews = pd.DataFrame(dataset.take(500_000))\nprint(\"Initial loaded shape:\", reviews.shape)\nprint(reviews.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:33:14.586194Z","iopub.execute_input":"2025-09-14T18:33:14.586432Z","iopub.status.idle":"2025-09-14T18:33:43.534389Z","shell.execute_reply.started":"2025-09-14T18:33:14.586408Z","shell.execute_reply":"2025-09-14T18:33:43.533658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"038c1d26bf204d5c99649e44ff193330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Amazon-Reviews-2023.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5a2e3ce1f94eb78571f46fc0acdb30"}},"metadata":{}},{"name":"stdout","text":"Initial loaded shape: (1000000, 10)\n   rating                                        title  \\\n0     3.0            Smells like gasoline! Going back!   \n1     1.0      Didn’t work at all lenses loose/broken.   \n2     5.0                                   Excellent!   \n3     5.0                       Great laptop backpack!   \n4     5.0  Best Headphones in the Fifties price range!   \n\n                                                text  \\\n0  First & most offensive: they reek of gasoline ...   \n1  These didn’t work. Idk if they were damaged in...   \n2  I love these. They even come with a carry case...   \n3  I was searching for a sturdy backpack for scho...   \n4  I've bought these headphones three times becau...   \n\n                                              images        asin parent_asin  \\\n0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n1                                                 []  B07N69T6TM  B07N69T6TM   \n2                                                 []  B01G8JO5F2  B01G8JO5F2   \n3                                                 []  B001OC5JKY  B001OC5JKY   \n4                                                 []  B013J7WUGC  B07CJYMRWM   \n\n                        user_id      timestamp  helpful_vote  \\\n0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1658185117948             0   \n1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1592678549731             0   \n2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1523093017534             0   \n3  AGGZ357AO26RQZVRLGU4D4N52DZQ  1290278495000            18   \n4  AG2L7H23R5LLKDKLBEF2Q3L2MVDA  1676601581238             0   \n\n   verified_purchase  \n0               True  \n1               True  \n2               True  \n3               True  \n4               True  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Rename columns\nreviews.rename(columns={\n    \"user_id\": \"reviewerID\",\n    \"asin\": \"asin\",\n    \"rating\": \"overall\",\n    \"text\": \"reviewText\",\n    \"timestamp\": \"unixReviewTime\"\n}, inplace=True)\n\n# Drop missing and duplicate entries\nreviews.dropna(subset=[\"reviewText\", \"overall\"], inplace=True)\nreviews.drop_duplicates(subset=[\"reviewerID\", \"asin\"], inplace=True)\n\n# Filter active users/items\nuser_counts = reviews[\"reviewerID\"].value_counts()\nitem_counts = reviews[\"asin\"].value_counts()\n\nreviews = reviews[reviews[\"reviewerID\"].isin(user_counts[user_counts >= 1].index)]\nreviews = reviews[reviews[\"asin\"].isin(item_counts[item_counts >= 1].index)]\n\n\nprint(\"Filtered dataset size:\", reviews.shape)\n\n# Train-test split\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(reviews, test_size=0.2, random_state=42)\n\n# Ground truth for evaluation\nground_truth = test_df.groupby('reviewerID')['asin'].apply(set).to_dict()\n\nprint(f\"Train size: {train_df.shape}, Test size: {test_df.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:33:43.535229Z","iopub.execute_input":"2025-09-14T18:33:43.535668Z","iopub.status.idle":"2025-09-14T18:33:50.179431Z","shell.execute_reply.started":"2025-09-14T18:33:43.535647Z","shell.execute_reply":"2025-09-14T18:33:50.178800Z"}},"outputs":[{"name":"stdout","text":"Filtered dataset size: (997501, 10)\nTrain size: (798000, 10), Test size: (199501, 10)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#4️⃣ Build Interaction Matrix + Train ALS\nfrom implicit.als import AlternatingLeastSquares\nfrom scipy.sparse import coo_matrix\n\n# Mapping\nuser_ids = train_df['reviewerID'].unique().tolist()\nitem_ids = train_df['asin'].unique().tolist()\nuser_map = {uid: idx for idx, uid in enumerate(user_ids)}\nitem_map = {pid: idx for idx, pid in enumerate(item_ids)}\nproduct_index_map = {idx: pid for idx, pid in enumerate(item_ids)}\n\n# Build interaction matrix\nrows = train_df['reviewerID'].map(user_map)\ncols = train_df['asin'].map(item_map)\nvals = train_df['overall']\n\nmatrix = coo_matrix((vals, (rows, cols)))\nmatrix_csr = matrix.tocsr()\n\n# Train ALS\nals = AlternatingLeastSquares(factors=128, regularization=0.1, iterations=50)\nals.fit(matrix_csr.T)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:33:50.180233Z","iopub.execute_input":"2025-09-14T18:33:50.180669Z","iopub.status.idle":"2025-09-14T18:36:00.261693Z","shell.execute_reply.started":"2025-09-14T18:33:50.180647Z","shell.execute_reply":"2025-09-14T18:36:00.260855Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 2 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n  check_blas_config()\n/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n  check_blas_config()\n/usr/local/lib/python3.11/dist-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 0.015363454818725586 seconds\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa878535df81471582bc116c7772f15a"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#5️⃣ Generate Product Embeddings (Content-Based)\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\nsemantic_model = SentenceTransformer('all-mpnet-base-v2')\n\n# Concatenate title + reviewText\nproduct_texts = train_df.groupby('asin')['reviewText'].apply(lambda x: ' '.join(x)).tolist()\nproduct_asins = train_df['asin'].unique().tolist()\nembeddings = semantic_model.encode(product_texts, convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:36:00.262605Z","iopub.execute_input":"2025-09-14T18:36:00.263102Z"}},"outputs":[{"name":"stderr","text":"2025-09-14 18:36:09.385615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757874969.579426      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757874969.631364      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8d5cd0950d42c0bb78be5ac53f7411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9576212e5a48422f82ab5bebacf38b10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32ef08c3a5fd4d1fa73030daefa7a216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d7527196d834b7ea826ee3a2f704d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e8e19009494d15b25bd29fc8466010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55ab5535a20846d5b5c72a8ec20adaf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc99eb0bdf9c4d7f965dd78de4b928a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02af2fb2ccb418da03bae435e4b3321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01a1421c2821479f9f45b70440c14803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e70335f765e44048296b748756302ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9151a92fdbdf41e69e06b15894b38095"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"#6️⃣ Semantic Search Function\ndef semantic_search(query, top_k=10):\n    query_embedding = semantic_model.encode([query], convert_to_tensor=True)\n    cos_scores = util.cos_sim(query_embedding, embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n    return [product_asins[idx] for idx in top_results.indices.cpu().numpy()]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hybrid_recommend(user_id, topn=10, alpha=0.6):\n    if user_id not in user_map:\n        return product_asins[:topn]\n\n    user_idx = user_map[user_id]\n    if user_idx >= als.user_factors.shape[0]:\n        return product_asins[:topn]\n\n    if user_idx >= matrix_csr.shape[0]:\n        return product_asins[:topn]\n\n    try:\n        item_indices, scores = als.recommend(user_idx, matrix_csr[user_idx], N=topn * 2)\n    except IndexError:\n        return product_asins[:topn]\n\n    hybrid_results = []\n    for item_idx, cf_score in zip(item_indices, scores):\n        if item_idx >= embeddings.shape[0]:\n            content_score = 0\n        else:\n            user_interactions = train_df[train_df['reviewerID'] == user_id]['asin'].tolist()\n\n            if user_interactions:\n                first_review_text = train_df[train_df['asin'] == user_interactions[0]]['reviewText'].values[0]\n                query_embedding = semantic_model.encode([first_review_text], convert_to_tensor=True)\n                sim_scores = util.cos_sim(query_embedding, embeddings)[0].cpu().numpy()\n                content_score = np.max(sim_scores)\n            else:\n                content_score = 0\n\n        final_score = alpha * cf_score + (1 - alpha) * content_score\n        hybrid_results.append((item_idx, final_score))\n\n    hybrid_results = sorted(hybrid_results, key=lambda x: -x[1])[:topn]\n\n    return [product_index_map.get(i, None) for i, _ in hybrid_results if i in product_index_map]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#8️⃣ Evaluation + MLflow Logging\nimport mlflow\nimport random\n\nsample_users = random.sample(list(ground_truth.keys()), min(1000, len(ground_truth)))\ntop_k = 10\nprecisions = []\nrecalls = []\n\nfor user_id in sample_users:\n    recommended_items = set(hybrid_recommend(user_id, topn=top_k, alpha=0.6))\n    true_items = ground_truth[user_id]\n\n    if not true_items:\n        continue\n\n    hits = len(recommended_items & true_items)\n    precision = hits / top_k\n    recall = hits / len(true_items)\n\n    precisions.append(precision)\n    recalls.append(recall)\n\navg_precision = sum(precisions) / len(precisions)\navg_recall = sum(recalls) / len(recalls)\n\nprint(f\"Precision@{top_k}: {avg_precision:.4f}\")\nprint(f\"Recall@{top_k}: {avg_recall:.4f}\")\n\nwith mlflow.start_run():\n    mlflow.log_param(\"top_k\", top_k)\n    mlflow.log_param(\"alpha\", 0.6)\n    mlflow.log_metric(f\"precision_at_{top_k}\", avg_precision)\n    mlflow.log_metric(f\"recall_at_{top_k}\", avg_recall)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_users = list(user_map.keys())[:5]\nfor user_id in sample_users:\n    print(f\"Recommendations for user {user_id}: {hybrid_recommend(user_id, topn=5)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}