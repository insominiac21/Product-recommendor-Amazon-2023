{"metadata":{"kernelspec":{"name":"","display_name":""},"language_info":{"name":""},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c75601ec-9865-4c66-ab26-1dfd6ed76f13","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b50c6663","cell_type":"markdown","source":"# Variant: Run with 50,000 sample rows (second phase)\n\nThis variant includes `SAMPLE_ROWS=50000`. To actually restrict the dataset to 50k rows, add `.sample(SAMPLE_ROWS, random_state=42)` to the cell that loads the CSV (or adapt that read to use SAMPLE_ROWS). The rest of the notebook is unchanged and contains detailed explanations before each original code cell.","metadata":{}},{"id":"4816d77c","cell_type":"code","source":"SAMPLE_ROWS = 50000  # set to 50000 to use a 50k-sample in the data-loading step\n","metadata":{},"outputs":[],"execution_count":null},{"id":"8faa5c94","cell_type":"markdown","source":"# Amazon Hybrid Recommender — Final Notebook\n\nComprehensive, runnable notebook containing prototype and scale stages, candidate generation, feature engineering, hard-negative mining, LightGBM ranking, diagnostics, and recommendations. This version contains full code and explanatory markdowns. Run cells sequentially. Some cells are resource-heavy (SBERT encoding, ALS, FAISS). The notebook includes CPU fallbacks for environments without `implicit` or `faiss`.","metadata":{"papermill":{"duration":0.005194,"end_time":"2025-09-28T17:25:11.074650","exception":false,"start_time":"2025-09-28T17:25:11.069456","status":"completed"},"tags":[]}},{"id":"bf1d06ce","cell_type":"markdown","source":"## How to run\n\n1. Run top-to-bottom. If your environment is offline or lacks `implicit`/`faiss`, the notebook falls back to CPU-friendly alternatives.\n2. The notebook writes artifact files to `OUT_DIR` (default `/kaggle/working`).\n3. If you install new packages mid-run (e.g., `implicit`), you may need to restart the kernel.\n","metadata":{"papermill":{"duration":0.006066,"end_time":"2025-09-28T17:25:11.086179","exception":false,"start_time":"2025-09-28T17:25:11.080113","status":"completed"},"tags":[]}},{"id":"d76021fb","cell_type":"markdown","source":"### Explanation for Cell 3\n\n**Purpose:** Imports libraries used later.\n\n**Line-by-line (short):**\n- `# Cell 1: Setup — Install-check and imports (non-blocking installs)` → Comment describing intent.\n- `# Optional: uncomment pip installs if you have internet and want to ensure all libs are present.` → Comment describing intent.\n- `!pip install -q datasets sentence-transformers scikit-learn lightgbm optuna joblib tqdm pandas scipy faiss-cpu implicit` → Performs a step relevant to data processing or modelling.\n- `import os, time, warnings, importlib` → Imports module(s).\n- `import numpy as np, pandas as pd, random, joblib` → Imports module(s).\n- `from collections import Counter, defaultdict` → Imports module(s).\n- `from scipy.sparse import csr_matrix` → Imports module(s).\n- `from tqdm.auto import tqdm` → Imports module(s).\n- `from math import log2` → Imports module(s).\n- `warnings.filterwarnings('ignore', category=UserWarning)` → Performs a step relevant to data processing or modelling.\n- `# Feature list and output directory (kept consistent with original notebook)` → Comment describing intent.\n- `OUT_DIR = '/kaggle/working'` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"213cb540","cell_type":"code","source":"# Cell 1: Setup — Install-check and imports (non-blocking installs)\n# Optional: uncomment pip installs if you have internet and want to ensure all libs are present.\n!pip install -q datasets sentence-transformers scikit-learn lightgbm optuna joblib tqdm pandas scipy faiss-cpu implicit\n\nimport os, time, warnings, importlib\nimport numpy as np, pandas as pd, random, joblib\nfrom collections import Counter, defaultdict\nfrom scipy.sparse import csr_matrix\nfrom tqdm.auto import tqdm\nfrom math import log2\n\nwarnings.filterwarnings('ignore', category=UserWarning)\n\n# Feature list and output directory (kept consistent with original notebook)\nOUT_DIR = '/kaggle/working'\nfeature_names = ['sem_score','sem_rank','als_score','als_rank','svd_score','svd_rank','pop_log','pop_rank','recency_days','title_len','txt_len','user_mean_rating','user_activity_count']\nfeat_cols = feature_names\nnow_ts = int(time.time() * 1000)\n\n# Flags for optional libs — later cells use these flags to decide runtime paths\nHAS_IMPLICIT = importlib.util.find_spec('implicit') is not None\nHAS_FAISS = importlib.util.find_spec('faiss') is not None\nHAS_SBERT = importlib.util.find_spec('sentence_transformers') is not None\n\nprint('Environment flags — HAS_SBERT:', HAS_SBERT, 'HAS_IMPLICIT:', HAS_IMPLICIT, 'HAS_FAISS:', HAS_FAISS)","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:25:11.097852Z","iopub.status.busy":"2025-09-28T17:25:11.097457Z","iopub.status.idle":"2025-09-28T17:26:33.352068Z","shell.execute_reply":"2025-09-28T17:26:33.351080Z"},"papermill":{"duration":82.261735,"end_time":"2025-09-28T17:26:33.353448","exception":false,"start_time":"2025-09-28T17:25:11.091713","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n","bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n","bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mEnvironment flags — HAS_SBERT: True HAS_IMPLICIT: True HAS_FAISS: True\n"]}],"execution_count":1},{"id":"920b28ec","cell_type":"markdown","source":"## 1 — Prototype Data Load (10k)\n\nLoad a small streaming sample (10k rows) from the Hugging Face Amazon Reviews dataset to iterate quickly and debug logic. This cell normalizes timestamps to milliseconds, drops records missing `asin` or `reviewerID`, and writes `sampled_reviews_10k.parquet` to `OUT_DIR`.","metadata":{"papermill":{"duration":0.02126,"end_time":"2025-09-28T17:26:33.395547","exception":false,"start_time":"2025-09-28T17:26:33.374287","status":"completed"},"tags":[]}},{"id":"bc835d8d","cell_type":"markdown","source":"### Explanation for Cell 5\n\n**Purpose:** Imports libraries used later. Saves results or models to disk.\n\n**Line-by-line (short):**\n- `# Prototype Data Load (10k)` → Comment describing intent.\n- `SAMPLE_N = 10000` → Performs a step relevant to data processing or modelling.\n- `HF_DATASET = 'McAuley-Lab/Amazon-Reviews-2023'` → Performs a step relevant to data processing or modelling.\n- `HF_CONFIG = 'raw_review_Electronics'` → Performs a step relevant to data processing or modelling.\n- `OUT_DIR = OUT_DIR if 'OUT_DIR' in globals() else '/kaggle/working'` → Performs a step relevant to data processing or modelling.\n- `from datasets import load_dataset` → Imports module(s).\n- `rows = []` → Performs a step relevant to data processing or modelling.\n- `cnt = 0` → Performs a step relevant to data processing or modelling.\n- `t0 = time.time()` → Performs a step relevant to data processing or modelling.\n- `ds_iter = load_dataset(HF_DATASET, HF_CONFIG, split='full', streaming=True, trust_remote_code=True)` → Performs a step relevant to data processing or modelling.\n- `for rec in ds_iter:` → Performs a step relevant to data processing or modelling.\n- `try:` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"9aaa3c51","cell_type":"code","source":"# Prototype Data Load (10k)\nSAMPLE_N = 10000\nHF_DATASET = 'McAuley-Lab/Amazon-Reviews-2023'\nHF_CONFIG = 'raw_review_Electronics'\nOUT_DIR = OUT_DIR if 'OUT_DIR' in globals() else '/kaggle/working'\n\nfrom datasets import load_dataset\n\nrows = []\ncnt = 0\nt0 = time.time()\nds_iter = load_dataset(HF_DATASET, HF_CONFIG, split='full', streaming=True, trust_remote_code=True)\nfor rec in ds_iter:\n    try:\n        asin = rec.get('asin') or rec.get('parent_asin')\n        user = rec.get('user_id') or rec.get('reviewerID')\n        text = rec.get('text') or rec.get('reviewText') or ''\n        overall = rec.get('rating') or rec.get('overall')\n        ts = rec.get('timestamp') or rec.get('unixReviewTime') or 0\n        helpful = rec.get('helpful_vote') or 0\n        if asin is None or user is None: \n            continue\n        ts_i = int(ts); ts_i = ts_i * 1000 if ts_i < 10**10 else ts_i\n        rows.append({'asin': str(asin), 'reviewerID': str(user), 'reviewText': str(text), 'overall': float(overall) if overall is not None else float('nan'), 'unixReviewTime': int(ts_i), 'helpful_vote': int(helpful)})\n        cnt += 1\n        if cnt >= SAMPLE_N: break\n    except Exception:\n        continue\ndf = pd.DataFrame(rows)\nos.makedirs(OUT_DIR, exist_ok=True)\ndf.to_parquet(f\"{OUT_DIR}/sampled_reviews_10k.parquet\", index=False)\nprint('Loaded', len(df), 'rows. Saved to', f\"{OUT_DIR}/sampled_reviews_10k.parquet\")","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:26:33.438241Z","iopub.status.busy":"2025-09-28T17:26:33.437876Z","iopub.status.idle":"2025-09-28T17:26:39.924199Z","shell.execute_reply":"2025-09-28T17:26:39.923216Z"},"papermill":{"duration":6.509003,"end_time":"2025-09-28T17:26:39.925496","exception":false,"start_time":"2025-09-28T17:26:33.416493","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79d1240b15e94222b2f180ae8f434dbc","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71c3f7d1ad504ee093a36af0fbf06396","version_major":2,"version_minor":0},"text/plain":["Amazon-Reviews-2023.py: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded 10000 rows. Saved to /kaggle/working/sampled_reviews_10k.parquet\n"]}],"execution_count":2},{"id":"05026fec","cell_type":"markdown","source":"### Build maps and interaction (prototype)\n\nCreate `item_map`, `user_map` and the sparse interaction matrix used by ALS and candidate generation.","metadata":{"papermill":{"duration":0.021475,"end_time":"2025-09-28T17:26:39.969301","exception":false,"start_time":"2025-09-28T17:26:39.947826","status":"completed"},"tags":[]}},{"id":"9bca3c5d","cell_type":"markdown","source":"### Explanation for Cell 7\n\n**Purpose:** Performs an operation relevant to the pipeline (see code).\n\n**Line-by-line (short):**\n- `# Build maps and interaction (prototype)` → Comment describing intent.\n- `unique_asins = sorted(df['asin'].unique().tolist())` → Performs a step relevant to data processing or modelling.\n- `unique_users = sorted(df['reviewerID'].unique().tolist())` → Performs a step relevant to data processing or modelling.\n- `item_map = {a:i for i,a in enumerate(unique_asins)}` → Performs a step relevant to data processing or modelling.\n- `inv_item_map = {i:a for a,i in item_map.items()}` → Performs a step relevant to data processing or modelling.\n- `user_map = {u:i for i,u in enumerate(unique_users)}` → Performs a step relevant to data processing or modelling.\n- `inv_user_map = {i:u for u,i in user_map.items()}` → Performs a step relevant to data processing or modelling.\n- `n_users, n_items = len(user_map), len(item_map)` → Performs a step relevant to data processing or modelling.\n- `u_idx = []; i_idx = []; data = []` → Performs a step relevant to data processing or modelling.\n- `for _, r in df.iterrows():` → Performs a step relevant to data processing or modelling.\n- `try:` → Performs a step relevant to data processing or modelling.\n- `u = user_map[r['reviewerID']]; i = item_map[r['asin']]` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"7a94153e","cell_type":"code","source":"# Build maps and interaction (prototype)\nunique_asins = sorted(df['asin'].unique().tolist())\nunique_users = sorted(df['reviewerID'].unique().tolist())\nitem_map = {a:i for i,a in enumerate(unique_asins)}\ninv_item_map = {i:a for a,i in item_map.items()}\nuser_map = {u:i for i,u in enumerate(unique_users)}\ninv_user_map = {i:u for u,i in user_map.items()}\n\nn_users, n_items = len(user_map), len(item_map)\nu_idx = []; i_idx = []; data = []\nfor _, r in df.iterrows():\n    try:\n        u = user_map[r['reviewerID']]; i = item_map[r['asin']]\n        w = float(r['overall']) if not pd.isna(r['overall']) else 1.0 + int(r.get('helpful_vote',0))\n        u_idx.append(u); i_idx.append(i); data.append(w)\n    except KeyError:\n        continue\n\ninteraction = csr_matrix((data, (u_idx, i_idx)), shape=(n_users, n_items)).tocsr()\nitem_user_matrix = interaction.T.tocsr()\npop_counts = Counter(df['asin'])\ntest_df_proto = df.groupby('reviewerID').tail(1).reset_index(drop=True)\nprint('Maps built:', n_users, 'users x', n_items, 'items')","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:26:40.013011Z","iopub.status.busy":"2025-09-28T17:26:40.012213Z","iopub.status.idle":"2025-09-28T17:26:40.475628Z","shell.execute_reply":"2025-09-28T17:26:40.474725Z"},"papermill":{"duration":0.487008,"end_time":"2025-09-28T17:26:40.477177","exception":false,"start_time":"2025-09-28T17:26:39.990169","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Maps built: 1561 users x 8907 items\n"]}],"execution_count":3},{"id":"340e6cfe","cell_type":"markdown","source":"## 2 — Helper functions & Feature Builder\n\nThis cell defines helper utilities used throughout the notebook:\n\n- `user_profile_emb`: compute a user's profile embedding (mean of item embeddings) with safe fallbacks.\n- `build_candidates_union`: aggregate candidates from semantic nearest neighbors, ALS, SVD, popularity and MF neighbors.\n- `build_features_for_candidates`: compute features used by the LightGBM reranker.\n\nAll functions include robust error handling so the notebook runs even if optional libraries are missing.","metadata":{"papermill":{"duration":0.020722,"end_time":"2025-09-28T17:26:40.519673","exception":false,"start_time":"2025-09-28T17:26:40.498951","status":"completed"},"tags":[]}},{"id":"59836002","cell_type":"markdown","source":"### Explanation for Cell 9\n\n**Purpose:** Imports libraries used later. Defines function(s) used downstream.\n\n**Line-by-line (short):**\n- `# Helper functions and feature builder (robust)` → Comment describing intent.\n- `import numpy as np, pandas as pd, math` → Imports module(s).\n- `from collections import defaultdict` → Imports module(s).\n- `# Ensure inv maps exist` → Comment describing intent.\n- `if 'inv_item_map' not in globals(): inv_item_map = {}` → Performs a step relevant to data processing or modelling.\n- `if 'inv_user_map' not in globals(): inv_user_map = {}` → Performs a step relevant to data processing or modelling.\n- `def user_profile_emb(uidx, emb_array, df_data, i_map, u_map):` → Performs a step relevant to data processing or modelling.\n- `# uid -> user string` → Comment describing intent.\n- `uid = None` → Performs a step relevant to data processing or modelling.\n- `if 'inv_user_map' in globals() and uidx in inv_user_map:` → Performs a step relevant to data processing or modelling.\n- `uid = inv_user_map.get(uidx)` → Performs a step relevant to data processing or modelling.\n- `if uid is None:` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"2dec65be","cell_type":"code","source":"# Helper functions and feature builder (robust)\nimport numpy as np, pandas as pd, math\nfrom collections import defaultdict\n\n# Ensure inv maps exist\nif 'inv_item_map' not in globals(): inv_item_map = {}\nif 'inv_user_map' not in globals(): inv_user_map = {}\n\ndef user_profile_emb(uidx, emb_array, df_data, i_map, u_map):\n    # uid -> user string\n    uid = None\n    if 'inv_user_map' in globals() and uidx in inv_user_map:\n        uid = inv_user_map.get(uidx)\n    if uid is None:\n        # fallback: if uidx already a string, try that\n        uid = uidx if isinstance(uidx, str) else None\n    if uid is None:\n        return emb_array.mean(axis=0)\n    item_list = df_data[df_data['reviewerID']==uid]['asin'].map(i_map).dropna().astype(int).tolist()\n    if item_list and len(item_list)>0:\n        return emb_array[item_list].mean(axis=0)\n    else:\n        return emb_array.mean(axis=0)\n\ndef build_candidates_union(uidx, emb_array, als_model, svd_facs, i_map, p_counts, u_map, df_data, inter_mat, top_sem=500, top_als=200, top_svd=200, top_pop=200, top_mf=200, max_cands=2000):\n    candidates = []; seen = set()\n    # semantic\n    if emb_array is not None:\n        try:\n            up = user_profile_emb(uidx, emb_array, df_data, i_map, u_map).astype('float32')\n            un = up / (np.linalg.norm(up) + 1e-9)\n            scores = emb_array.dot(un)\n            sem_idxs = np.argsort(-scores)[:top_sem]\n            for it in map(int, sem_idxs):\n                if it not in seen: seen.add(it); candidates.append(it)\n        except Exception:\n            pass\n    # ALS recommend\n    if als_model is not None:\n        try:\n            rec = als_model.recommend(uidx, inter_mat[uidx], N=top_als)\n            als_list = []\n            if isinstance(rec, list) and len(rec)>0 and isinstance(rec[0], (list,tuple)):\n                als_list = [int(r[0]) for r in rec]\n            elif isinstance(rec, tuple) and len(rec)==2:\n                als_list = [int(x) for x in rec[0]]\n            else:\n                try:\n                    als_list = [int(r[0]) if isinstance(r,(list,tuple)) else int(r) for r in rec]\n                except Exception:\n                    als_list = []\n            for it in als_list:\n                if it not in seen: seen.add(it); candidates.append(it)\n        except Exception:\n            pass\n    # SVD global similarity\n    if svd_facs is not None:\n        try:\n            user_vec = svd_facs.mean(axis=0)\n            svd_scores = svd_facs.dot(user_vec)\n            svd_idx = np.argsort(-svd_scores)[:top_svd]\n            for it in map(int, svd_idx):\n                if it not in seen: seen.add(it); candidates.append(it)\n        except Exception:\n            pass\n    # popularity\n    try:\n        pop_list = [i_map.get(a) for a,_ in p_counts.most_common(top_pop) if a in i_map]\n        for it in pop_list:\n            if it not in seen: seen.add(it); candidates.append(it)\n    except Exception:\n        pass\n    # MF neighbors (approx via item factors if available)\n    try:\n        if als_model is not None and hasattr(als_model, 'item_factors'):\n            item_facs = als_model.item_factors\n            user_items = inter_mat[uidx].indices.tolist() if hasattr(inter_mat[uidx], 'indices') else []\n            for it in user_items[:5]:\n                vec = item_facs[it]\n                sim = item_facs.dot(vec)\n                neigh = np.argsort(-sim)[:top_mf]\n                for ni in map(int, neigh):\n                    if ni not in seen: seen.add(ni); candidates.append(ni)\n    except Exception:\n        pass\n    return candidates[:max_cands]\n\ndef build_features_for_candidates(uidx, cands, emb_array, als_facs, als_u_facs, svd_facs, df_data, i_map, u_map, p_counts, feat_names, now_ts):\n    n = len(cands); X = np.zeros((n, len(feat_names)), dtype=float)\n    # user emb\n    try:\n        uemb = user_profile_emb(uidx, emb_array, df_data, i_map, u_map); uembn = uemb/(np.linalg.norm(uemb)+1e-9)\n    except Exception:\n        uembn = emb_array.mean(axis=0); uembn = uembn/(np.linalg.norm(uembn)+1e-9)\n    # sem\n    try:\n        sem_scores = (emb_array[cands] * uembn).sum(axis=1)\n        X[:, feat_names.index('sem_score')] = sem_scores\n        ranks = np.empty(n, dtype=int); ranks[np.argsort(-sem_scores)] = np.arange(n); X[:, feat_names.index('sem_rank')] = ranks\n    except Exception:\n        pass\n    # als\n    try:\n        if als_facs is not None and als_u_facs is not None:\n            uf = als_u_facs[uidx] if uidx < als_u_facs.shape[0] else als_facs.mean(axis=0)\n            als_scores = np.dot(als_facs[cands], uf)\n            X[:, feat_names.index('als_score')] = als_scores\n            ranks = np.empty(n, dtype=int); ranks[np.argsort(-als_scores)] = np.arange(n); X[:, feat_names.index('als_rank')] = ranks\n    except Exception:\n        pass\n    # svd\n    try:\n        if svd_facs is not None:\n            user_fact = svd_facs.mean(axis=0); svd_scores = svd_facs[cands].dot(user_fact)\n            X[:, feat_names.index('svd_score')] = svd_scores; ranks = np.empty(n, dtype=int); ranks[np.argsort(-svd_scores)] = np.arange(n); X[:, feat_names.index('svd_rank')] = ranks\n    except Exception:\n        pass\n    # pop & recency\n    try:\n        pop_vals = np.array([p_counts.get(inv_item_map.get(i, ''), 0) for i in cands], dtype=float)\n        X[:, feat_names.index('pop_log')] = np.log1p(pop_vals); ranks = np.empty(n,dtype=int); ranks[np.argsort(-pop_vals)] = np.arange(n); X[:, feat_names.index('pop_rank')] = ranks\n        recency_ms = np.array([item_last_ts.get(inv_item_map.get(i, ''), 0) for i in cands], dtype=float); X[:, feat_names.index('recency_days')] = ((now_ts - recency_ms)/(1000*60*60*24)).clip(min=0)\n    except Exception:\n        pass\n    # text & user stats\n    try:\n        title_len=[]; txt_len=[]\n        for idx in cands:\n            asin = inv_item_map.get(idx, ''); rows_sub = df_data[df_data['asin']==asin]\n            title = rows_sub['title'].iloc[0] if ('title' in rows_sub.columns and len(rows_sub)>0 and pd.notna(rows_sub['title'].iloc[0])) else ''\n            text = rows_sub['reviewText'].iloc[0] if ('reviewText' in rows_sub.columns and len(rows_sub)>0 and pd.notna(rows_sub['reviewText'].iloc[0])) else ''\n            title_len.append(len(str(title))); txt_len.append(len(str(text)))\n        X[:, feat_names.index('title_len')] = np.array(title_len); X[:, feat_names.index('txt_len')] = np.array(txt_len)\n        uid = inv_user_map.get(uidx, None); user_rows = df_data[df_data['reviewerID']==uid] if uid else pd.DataFrame()\n        X[:, feat_names.index('user_mean_rating')] = float(user_rows['overall'].mean() if len(user_rows)>0 else 0.0); X[:, feat_names.index('user_activity_count')] = float(len(user_rows))\n    except Exception:\n        pass\n    return {'X': X, 'cands': cands, 'feature_names': feat_names}","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:26:40.621384Z","iopub.status.busy":"2025-09-28T17:26:40.621116Z","iopub.status.idle":"2025-09-28T17:26:40.644468Z","shell.execute_reply":"2025-09-28T17:26:40.643868Z"},"papermill":{"duration":0.105251,"end_time":"2025-09-28T17:26:40.645641","exception":false,"start_time":"2025-09-28T17:26:40.540390","status":"completed"},"tags":[]},"outputs":[],"execution_count":4},{"id":"06fb1912","cell_type":"markdown","source":"## 3 — Hard-negative mining (prototype)\n\nCreate meta-training pairs (pos/neg) for the LTR model. This prototype uses a combination of hard negatives (top-ranked non-pos by ALS/SVD) and random negatives.","metadata":{"papermill":{"duration":0.020954,"end_time":"2025-09-28T17:26:40.688330","exception":false,"start_time":"2025-09-28T17:26:40.667376","status":"completed"},"tags":[]}},{"id":"f05bb502","cell_type":"markdown","source":"### Explanation for Cell 11\n\n**Purpose:** Imports libraries used later.\n\n**Line-by-line (short):**\n- `# Hard-negative mining (prototype)` → Comment describing intent.\n- `import random` → Imports module(s).\n- `USERS_TO_USE = 300; HARD_NEG_PER_POS = 60; RANDOM_NEG_PER_POS = 5` → Performs a step relevant to data processing or modelling.\n- `meta_rows = []; all_users = list(df['reviewerID'].unique()); sample_users = all_users[:min(USERS_TO_USE, len(all_users))]` → Performs a step relevant to data processing or modelling.\n- `for uid in tqdm(sample_users, desc='Building Meta Prototype'):` → Performs a step relevant to data processing or modelling.\n- `uidx = user_map.get(uid);` → Performs a step relevant to data processing or modelling.\n- `if uidx is None: continue` → Performs a step relevant to data processing or modelling.\n- `cands = build_candidates_union(uidx, None, None, None, item_map, pop_counts, user_map, df, interaction, top_sem=500, top_als=200, top_svd=200, top_pop=200, max_cands=1000)` → Performs a step relevant to data processing or modelling.\n- `if not cands: continue` → Performs a step relevant to data processing or modelling.\n- `mf = build_features_for_candidates(uidx, cands, np.zeros((len(item_map), 768)), None, None, None, df, item_map, user_map, pop_counts, feature_names, now_ts)` → Performs a step relevant to data processing or modelling.\n- `Xc = mf['X']; cidx = mf['cands']; fns = mf['feature_names']` → Performs a step relevant to data processing or modelling.\n- `true_asins = test_df_proto[test_df_proto['reviewerID']==uid]['asin'].tolist(); true_idxs = [item_map[a] for a in true_asins if a in item_map]` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"38dc1a6f","cell_type":"code","source":"# Hard-negative mining (prototype)\nimport random\nUSERS_TO_USE = 300; HARD_NEG_PER_POS = 60; RANDOM_NEG_PER_POS = 5\nmeta_rows = []; all_users = list(df['reviewerID'].unique()); sample_users = all_users[:min(USERS_TO_USE, len(all_users))]\nfor uid in tqdm(sample_users, desc='Building Meta Prototype'):\n    uidx = user_map.get(uid); \n    if uidx is None: continue\n    cands = build_candidates_union(uidx, None, None, None, item_map, pop_counts, user_map, df, interaction, top_sem=500, top_als=200, top_svd=200, top_pop=200, max_cands=1000)\n    if not cands: continue\n    mf = build_features_for_candidates(uidx, cands, np.zeros((len(item_map), 768)), None, None, None, df, item_map, user_map, pop_counts, feature_names, now_ts)\n    Xc = mf['X']; cidx = mf['cands']; fns = mf['feature_names']\n    true_asins = test_df_proto[test_df_proto['reviewerID']==uid]['asin'].tolist(); true_idxs = [item_map[a] for a in true_asins if a in item_map]\n    if not true_idxs: continue\n    als_col = Xc[:, fns.index('als_score')] if 'als_score' in fns else np.zeros(Xc.shape[0])\n    svd_col = Xc[:, fns.index('svd_score')] if 'svd_score' in fns else np.zeros(Xc.shape[0])\n    hard_score = 0.5 * als_col + 0.5 * svd_col\n    cand_arr = np.array(cidx); pos_mask = np.isin(cand_arr, true_idxs); non_pos_idx = np.where(~pos_mask)[0]\n    if len(non_pos_idx)==0: continue\n    ordering = non_pos_idx[np.argsort(-hard_score[non_pos_idx])]; hard_negs_idx = ordering[:HARD_NEG_PER_POS].tolist()\n    remaining = list(set(non_pos_idx.tolist()) - set(hard_negs_idx)); random_negs_idx = random.sample(remaining, min(RANDOM_NEG_PER_POS, len(remaining))) if remaining else []\n    for t in true_idxs:\n        pos_loc = np.where(cand_arr==t)[0]; \n        if len(pos_loc)==0: continue\n        for p in pos_loc:\n            row = {'user_idx': uidx, 'item_idx': int(cidx[p]), 'label': 1}\n            for j,fn in enumerate(fns):\n                try: row[fn] = float(Xc[p,j])\n                except: row[fn] = 0.0\n            meta_rows.append(row)\n            for idx in hard_negs_idx:\n                rn = {'user_idx': uidx, 'item_idx': int(cidx[idx]), 'label': 0}\n                for j,fn in enumerate(fns):\n                    try: rn[fn] = float(Xc[idx,j])\n                    except: rn[fn] = 0.0\n                meta_rows.append(rn)\n            for idx in random_negs_idx:\n                rr = {'user_idx': uidx, 'item_idx': int(cidx[idx]), 'label': 0}\n                for j,fn in enumerate(fns):\n                    try: rr[fn] = float(Xc[idx,j])\n                    except: rr[fn] = 0.0\n                meta_rows.append(rr)\nmeta_df_small = pd.DataFrame(meta_rows).sample(frac=1.0, random_state=42).reset_index(drop=True)\nmeta_df_small.to_parquet(f\"{OUT_DIR}/meta_enhanced_small.parquet\", index=False)\nprint('meta_df_small shape:', meta_df_small.shape)","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:26:40.731947Z","iopub.status.busy":"2025-09-28T17:26:40.731298Z","iopub.status.idle":"2025-09-28T17:27:51.563807Z","shell.execute_reply":"2025-09-28T17:27:51.562909Z"},"papermill":{"duration":70.855965,"end_time":"2025-09-28T17:27:51.565442","exception":false,"start_time":"2025-09-28T17:26:40.709477","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc7a7d6010574a849d4808effeb20c64","version_major":2,"version_minor":0},"text/plain":["Building Meta Prototype:   0%|          | 0/300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["meta_df_small shape: (2640, 16)\n"]}],"execution_count":5},{"id":"a05e05b8","cell_type":"markdown","source":"## 4 — LightGBM Tuning & Prototype Training\n\nUse Optuna to tune lambdarank hyperparameters. Important: set `feature_pre_filter=False` so trials changing `min_data_in_leaf` don't error.","metadata":{"papermill":{"duration":0.022205,"end_time":"2025-09-28T17:27:51.610896","exception":false,"start_time":"2025-09-28T17:27:51.588691","status":"completed"},"tags":[]}},{"id":"c7b901bc","cell_type":"markdown","source":"### Explanation for Cell 13\n\n**Purpose:** Imports libraries used later. Defines function(s) used downstream. Trains a model / fits parameters. Produces predictions on data.\n\n**Line-by-line (short):**\n- `# LightGBM tuning & training (prototype)` → Comment describing intent.\n- `import lightgbm as lgb, optuna` → Imports module(s).\n- `from sklearn.model_selection import train_test_split` → Imports module(s).\n- `from math import log2` → Imports module(s).\n- `feat_cols = [c for c in meta_df_small.columns if c not in ('user_idx','item_idx','label')]` → Performs a step relevant to data processing or modelling.\n- `users = meta_df_small['user_idx'].unique(); train_u, valid_u = train_test_split(list(users), test_size=0.20, random_state=42)` → Performs a step relevant to data processing or modelling.\n- `tr_mask = meta_df_small['user_idx'].isin(train_u); val_mask = meta_df_small['user_idx'].isin(valid_u)` → Performs a step relevant to data processing or modelling.\n- `X_tr = meta_df_small[tr_mask][feat_cols].values; y_tr = meta_df_small[tr_mask]['label'].values` → Performs a step relevant to data processing or modelling.\n- `gr_tr = meta_df_small[tr_mask].groupby('user_idx', sort=False).size().astype(int).values` → Groups and aggregates data.\n- `X_val = meta_df_small[val_mask][feat_cols].values; y_val = meta_df_small[val_mask]['label'].values` → Performs a step relevant to data processing or modelling.\n- `gr_val = meta_df_small[val_mask].groupby('user_idx', sort=False).size().astype(int).values` → Groups and aggregates data.\n- `dtrain = lgb.Dataset(X_tr, label=y_tr, group=gr_tr); dval = lgb.Dataset(X_val, label=y_val, group=gr_val, reference=dtrain)` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"47d8d05d","cell_type":"code","source":"# LightGBM tuning & training (prototype)\nimport lightgbm as lgb, optuna\nfrom sklearn.model_selection import train_test_split\nfrom math import log2\n\nfeat_cols = [c for c in meta_df_small.columns if c not in ('user_idx','item_idx','label')]\nusers = meta_df_small['user_idx'].unique(); train_u, valid_u = train_test_split(list(users), test_size=0.20, random_state=42)\ntr_mask = meta_df_small['user_idx'].isin(train_u); val_mask = meta_df_small['user_idx'].isin(valid_u)\nX_tr = meta_df_small[tr_mask][feat_cols].values; y_tr = meta_df_small[tr_mask]['label'].values\ngr_tr = meta_df_small[tr_mask].groupby('user_idx', sort=False).size().astype(int).values\nX_val = meta_df_small[val_mask][feat_cols].values; y_val = meta_df_small[val_mask]['label'].values\ngr_val = meta_df_small[val_mask].groupby('user_idx', sort=False).size().astype(int).values\ndtrain = lgb.Dataset(X_tr, label=y_tr, group=gr_tr); dval = lgb.Dataset(X_val, label=y_val, group=gr_val, reference=dtrain)\n\ndef ndcg_per_group(preds, df_masked, K=10):\n    eval_users = df_masked['user_idx'].unique(); idx = 0; ndcgs = []\n    for u in eval_users:\n        sub = df_masked[df_masked['user_idx']==u]; n = len(sub)\n        if n==0: continue\n        p = preds[idx: idx + n]; items = sub['item_idx'].values; order = np.argsort(-p); ranked = items[order].tolist()\n        true_items = sub['item_idx'][sub['label']==1].tolist()\n        gains = [1.0 if it in true_items else 0.0 for it in ranked[:K]]\n        dcg = sum(g / log2(i+2) for i,g in enumerate(gains)); idcg = sum(1.0 / log2(i+2) for i in range(min(len(true_items), K))) if len(true_items)>0 else 0.0\n        ndcgs.append(dcg/idcg if idcg>0 else 0.0); idx += n\n    return float(np.mean(ndcgs)) if len(ndcgs)>0 else 0.0\n\ndef objective(trial):\n    param = {'objective':'lambdarank','metric':'ndcg','ndcg_eval_at':[10],\n             'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n             'num_leaves': trial.suggest_int('num_leaves', 31, 127),\n             'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n             'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n             'verbosity': -1, 'seed': 42, 'feature_pre_filter': False}\n    try:\n        bst = lgb.train(param, dtrain, num_boost_round=500, valid_sets=[dval], callbacks=[lgb.early_stopping(stopping_rounds=40), lgb.log_evaluation(period=0)])\n        preds_val = bst.predict(X_val); df_val = meta_df_small[val_mask].copy().reset_index(drop=True)\n        return -ndcg_per_group(preds_val, df_val, K=10)\n    except Exception as e:\n        print('LightGBM failed in objective:', e); return 1.0\n\nstudy = optuna.create_study(direction='minimize'); study.optimize(objective, n_trials=20, show_progress_bar=True)\nbest_params_proto = study.best_params; print('Best params:', best_params_proto)\n\nparams = {'objective':'lambdarank','metric':'ndcg','ndcg_eval_at':[10,50],\n          'learning_rate':float(best_params_proto.get('learning_rate',0.05)),\n          'num_leaves':int(best_params_proto.get('num_leaves',63)),\n          'min_data_in_leaf':int(best_params_proto.get('min_data_in_leaf',20)),\n          'feature_fraction':float(best_params_proto.get('feature_fraction',0.8)),'verbosity':-1,'seed':42,'feature_pre_filter':False}\nbst_proto = lgb.train(params, dtrain, num_boost_round=1000, valid_sets=[dval], callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=100)])\njoblib.dump(bst_proto, f\"{OUT_DIR}/lgbm_reranker_prototype.joblib\")","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:27:51.656680Z","iopub.status.busy":"2025-09-28T17:27:51.656000Z","iopub.status.idle":"2025-09-28T17:27:57.449478Z","shell.execute_reply":"2025-09-28T17:27:57.448738Z"},"papermill":{"duration":5.817473,"end_time":"2025-09-28T17:27:57.450644","exception":false,"start_time":"2025-09-28T17:27:51.633171","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2025-09-28 17:27:56,145] A new study created in memory with name: no-name-bec263d3-a782-441e-a239-bd0c365d7010\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6580dfa1754542349eb39d38743871f1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[112]\tvalid_0's ndcg@10: 0.378289\n","[I 2025-09-28 17:27:56,302] Trial 0 finished with value: -0.0 and parameters: {'learning_rate': 0.06285006506553868, 'num_leaves': 105, 'min_data_in_leaf': 141, 'feature_fraction': 0.7666390050012435}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[2]\tvalid_0's ndcg@10: 0.291667\n","[I 2025-09-28 17:27:56,343] Trial 1 finished with value: -0.0 and parameters: {'learning_rate': 0.006742551600441457, 'num_leaves': 71, 'min_data_in_leaf': 135, 'feature_fraction': 0.8345589764176576}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[4]\tvalid_0's ndcg@10: 0.339961\n","[I 2025-09-28 17:27:56,387] Trial 2 finished with value: -0.0 and parameters: {'learning_rate': 0.002441114465935709, 'num_leaves': 92, 'min_data_in_leaf': 95, 'feature_fraction': 0.7099156448273646}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[8]\tvalid_0's ndcg@10: 0.362777\n","[I 2025-09-28 17:27:56,436] Trial 3 finished with value: -0.0 and parameters: {'learning_rate': 0.0013317911288796497, 'num_leaves': 85, 'min_data_in_leaf': 93, 'feature_fraction': 0.9747959668994488}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[8]\tvalid_0's ndcg@10: 0.362777\n","[I 2025-09-28 17:27:56,485] Trial 4 finished with value: -0.0 and parameters: {'learning_rate': 0.0030959181691401615, 'num_leaves': 86, 'min_data_in_leaf': 88, 'feature_fraction': 0.7771471363404697}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[6]\tvalid_0's ndcg@10: 0.366077\n","[I 2025-09-28 17:27:56,543] Trial 5 finished with value: -0.0 and parameters: {'learning_rate': 0.013775826155733414, 'num_leaves': 121, 'min_data_in_leaf': 58, 'feature_fraction': 0.9984249362559945}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[47]\tvalid_0's ndcg@10: 0.416667\n","[I 2025-09-28 17:27:56,631] Trial 6 finished with value: -0.0 and parameters: {'learning_rate': 0.06286806450358125, 'num_leaves': 64, 'min_data_in_leaf': 59, 'feature_fraction': 0.633781270726169}. Best is trial 0 with value: -0.0.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[3]\tvalid_0's ndcg@10: 0.397781\n","[I 2025-09-28 17:27:56,676] Trial 7 finished with value: -0.1019331095982161 and parameters: {'learning_rate': 0.0019798048515999225, 'num_leaves': 71, 'min_data_in_leaf': 110, 'feature_fraction': 0.5251504669633669}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[5]\tvalid_0's ndcg@10: 0.380478\n","[I 2025-09-28 17:27:56,723] Trial 8 finished with value: -0.0 and parameters: {'learning_rate': 0.06495359515311722, 'num_leaves': 85, 'min_data_in_leaf': 83, 'feature_fraction': 0.9881926861206954}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[2]\tvalid_0's ndcg@10: 0.419911\n","[I 2025-09-28 17:27:56,772] Trial 9 finished with value: -0.0 and parameters: {'learning_rate': 0.05511976155103526, 'num_leaves': 110, 'min_data_in_leaf': 53, 'feature_fraction': 0.5952410126477097}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[6]\tvalid_0's ndcg@10: 0.321429\n","[I 2025-09-28 17:27:56,831] Trial 10 finished with value: -0.0 and parameters: {'learning_rate': 0.018011452885329775, 'num_leaves': 33, 'min_data_in_leaf': 197, 'feature_fraction': 0.5241055917328087}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[26]\tvalid_0's ndcg@10: 0.351114\n","[I 2025-09-28 17:27:56,898] Trial 11 finished with value: -0.0 and parameters: {'learning_rate': 0.02288201911461718, 'num_leaves': 54, 'min_data_in_leaf': 146, 'feature_fraction': 0.8309999445170951}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[1]\tvalid_0's ndcg@10: 0.323904\n","[I 2025-09-28 17:27:56,950] Trial 12 finished with value: -0.039433109598216096 and parameters: {'learning_rate': 0.003983143879977324, 'num_leaves': 104, 'min_data_in_leaf': 138, 'feature_fraction': 0.696139256546486}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[7]\tvalid_0's ndcg@10: 0.410231\n","[I 2025-09-28 17:27:57,037] Trial 13 finished with value: -0.0 and parameters: {'learning_rate': 0.005553462735152578, 'num_leaves': 52, 'min_data_in_leaf': 11, 'feature_fraction': 0.5013631622871864}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[9]\tvalid_0's ndcg@10: 0.328013\n","[I 2025-09-28 17:27:57,092] Trial 14 finished with value: -0.036133103289735985 and parameters: {'learning_rate': 0.0010622066924490287, 'num_leaves': 102, 'min_data_in_leaf': 192, 'feature_fraction': 0.6555515569346979}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[3]\tvalid_0's ndcg@10: 0.311588\n","[I 2025-09-28 17:27:57,147] Trial 15 finished with value: -0.07886621919643219 and parameters: {'learning_rate': 0.002430468399753114, 'num_leaves': 125, 'min_data_in_leaf': 168, 'feature_fraction': 0.5655113614064305}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[3]\tvalid_0's ndcg@10: 0.311588\n","[I 2025-09-28 17:27:57,198] Trial 16 finished with value: -0.07886621919643219 and parameters: {'learning_rate': 0.001902821152188094, 'num_leaves': 126, 'min_data_in_leaf': 170, 'feature_fraction': 0.5646908577411782}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[22]\tvalid_0's ndcg@10: 0.340023\n","[I 2025-09-28 17:27:57,265] Trial 17 finished with value: -0.0 and parameters: {'learning_rate': 0.008121894334506143, 'num_leaves': 71, 'min_data_in_leaf': 117, 'feature_fraction': 0.569182830289084}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[3]\tvalid_0's ndcg@10: 0.33779\n","[I 2025-09-28 17:27:57,320] Trial 18 finished with value: -0.0 and parameters: {'learning_rate': 0.003909117997350036, 'num_leaves': 43, 'min_data_in_leaf': 167, 'feature_fraction': 0.6009303206924289}. Best is trial 7 with value: -0.1019331095982161.\n","Training until validation scores don't improve for 40 rounds\n","Early stopping, best iteration is:\n","[31]\tvalid_0's ndcg@10: 0.33449\n","[I 2025-09-28 17:27:57,399] Trial 19 finished with value: -0.0 and parameters: {'learning_rate': 0.0017403790035826776, 'num_leaves': 118, 'min_data_in_leaf': 115, 'feature_fraction': 0.5004345665586029}. Best is trial 7 with value: -0.1019331095982161.\n","Best params: {'learning_rate': 0.0019798048515999225, 'num_leaves': 71, 'min_data_in_leaf': 110, 'feature_fraction': 0.5251504669633669}\n","Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[3]\tvalid_0's ndcg@10: 0.397781\tvalid_0's ndcg@50: 0.427224\n"]},{"data":{"text/plain":["['/kaggle/working/lgbm_reranker_prototype.joblib']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"id":"df6e2206","cell_type":"markdown","source":"## 5 — Scale-up Data Load (100k) & Model Initialization\n\nThis cell builds a larger sample (100k rows) and computes final embeddings and factors. It prefers SBERT/implicit/FAISS when available but includes CPU-friendly fallbacks (TF-IDF + SVD and TruncatedSVD-based MF) so the notebook runs offline.","metadata":{"papermill":{"duration":0.022771,"end_time":"2025-09-28T17:27:57.496495","exception":false,"start_time":"2025-09-28T17:27:57.473724","status":"completed"},"tags":[]}},{"id":"2a920c43","cell_type":"markdown","source":"### Explanation for Cell 15\n\n**Purpose:** Imports libraries used later. Trains a model / fits parameters.\n\n**Line-by-line (short):**\n- `# Scale-up data load (100k) with fallbacks` → Comment describing intent.\n- `SCALE_N = 10000` → Performs a step relevant to data processing or modelling.\n- `SBERT_MODEL_FINAL = 'all-mpnet-base-v2'` → Performs a step relevant to data processing or modelling.\n- `from datasets import load_dataset` → Imports module(s).\n- `ds_iter = load_dataset('McAuley-Lab/Amazon-Reviews-2023', 'raw_review_Electronics', split='full', streaming=True, trust_remote_code=True)` → Performs a step relevant to data processing or modelling.\n- `rows = []; cnt = 0` → Performs a step relevant to data processing or modelling.\n- `for rec in ds_iter:` → Performs a step relevant to data processing or modelling.\n- `try:` → Performs a step relevant to data processing or modelling.\n- `asin = rec.get('asin') or rec.get('parent_asin'); user = rec.get('user_id') or rec.get('reviewerID'); text = rec.get('text') or rec.get('reviewText') or ''` → Performs a step relevant to data processing or modelling.\n- `overall = rec.get('rating') or rec.get('overall'); ts = rec.get('timestamp') or rec.get('unixReviewTime') or 0` → Performs a step relevant to data processing or modelling.\n- `if asin is None or user is None: continue` → Performs a step relevant to data processing or modelling.\n- `ts_i = int(ts); ts_i = ts_i*1000 if ts_i < 10**10 else ts_i` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"ae5a78d2","cell_type":"code","source":"# Scale-up data load (100k) with fallbacks\nSCALE_N = 10000\nSBERT_MODEL_FINAL = 'all-mpnet-base-v2'\n\nfrom datasets import load_dataset\nds_iter = load_dataset('McAuley-Lab/Amazon-Reviews-2023', 'raw_review_Electronics', split='full', streaming=True, trust_remote_code=True)\nrows = []; cnt = 0\nfor rec in ds_iter:\n    try:\n        asin = rec.get('asin') or rec.get('parent_asin'); user = rec.get('user_id') or rec.get('reviewerID'); text = rec.get('text') or rec.get('reviewText') or ''\n        overall = rec.get('rating') or rec.get('overall'); ts = rec.get('timestamp') or rec.get('unixReviewTime') or 0\n        if asin is None or user is None: continue\n        ts_i = int(ts); ts_i = ts_i*1000 if ts_i < 10**10 else ts_i\n        rows.append({'asin':str(asin),'reviewerID':str(user),'reviewText':str(text),'overall':float(overall) if overall is not None else float('nan'),'unixReviewTime':int(ts_i)})\n        cnt += 1\n        if cnt >= SCALE_N: break\n    except Exception:\n        continue\ndf_scale = pd.DataFrame(rows)\nunique_asins_scale = sorted(df_scale['asin'].unique().tolist()); unique_users_scale = sorted(df_scale['reviewerID'].unique().tolist())\nitem_map_scale = {a:i for i,a in enumerate(unique_asins_scale)}; inv_item_map_scale = {i:a for a,i in item_map_scale.items()}\nuser_map_scale = {u:i for i,u in enumerate(unique_users_scale)}; inv_user_map_scale = {i:u for u,i in user_map_scale.items()}\nn_users_scale, n_items_scale = len(user_map_scale), len(item_map_scale)\nu_idx=[]; i_idx=[]; data=[]\nfor _, r in df_scale.iterrows():\n    try:\n        u = user_map_scale[r['reviewerID']]; i = item_map_scale[r['asin']]\n        w = float(r['overall']) if not pd.isna(r['overall']) else 1.0; u_idx.append(u); i_idx.append(i); data.append(w)\n    except KeyError: continue\ninteraction_scale = csr_matrix((data,(u_idx,i_idx)), shape=(n_users_scale,n_items_scale)).tocsr()\nitem_user_matrix_scale = interaction_scale.T.tocsr()\npop_counts_scale = Counter(df_scale['asin'])\ntest_df_scale = df_scale.groupby('reviewerID').tail(1).reset_index(drop=True)\n\n# Build semantic embeddings: SBERT if available else TF-IDF+SVD fallback\nif HAS_SBERT:\n    from sentence_transformers import SentenceTransformer\n    sbert_final = SentenceTransformer(SBERT_MODEL_FINAL, device='cpu')\n    agg = defaultdict(list)\n    for _, r in df_scale[['asin','reviewText']].iterrows():\n        a = r['asin']\n        if len(agg[a]) < 5: agg[a].append(str(r['reviewText'])[:1200])\n    texts = [' . '.join(agg.get(a, [''])) for a in sorted(item_map_scale.keys(), key=lambda x: item_map_scale[x])]\n    emb_batches = []; batch_size = 256\n    for i in tqdm(range(0, len(texts), batch_size), desc='SBERT encode'):\n        emb = sbert_final.encode(texts[i:i+batch_size], convert_to_numpy=True, show_progress_bar=False)\n        emb_batches.append(emb)\n    item_emb_final = np.vstack(emb_batches).astype('float32')\nelse:\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.decomposition import TruncatedSVD as _TSVD\n    agg = defaultdict(list)\n    for _, r in df_scale[['asin','reviewText']].iterrows():\n        a = r['asin']\n        if len(agg[a]) < 5: agg[a].append(str(r['reviewText'])[:1200])\n    texts = [' . '.join(agg.get(a, [''])) for a in sorted(item_map_scale.keys(), key=lambda x: item_map_scale[x])]\n    tf = TfidfVectorizer(max_features=65536, ngram_range=(1,2), min_df=2)\n    Xtf = tf.fit_transform(texts)\n    svd_text = _TSVD(n_components=384, random_state=42)\n    item_emb_final = svd_text.fit_transform(Xtf).astype('float32')\n\n# Build MF factors: implicit ALS if available else TruncatedSVD fallback\nif HAS_IMPLICIT:\n    try:\n        from implicit.als import AlternatingLeastSquares\n        als_model_final = AlternatingLeastSquares(factors=128, regularization=0.1, iterations=20, use_gpu=False)\n        als_model_final.fit(item_user_matrix_scale.astype('float32'))\n        als_item_factors_final = als_model_final.item_factors; als_user_factors_final = als_model_final.user_factors\n    except Exception:\n        # fallback to SVD factors below\n        HAS_IMPLICIT = False\n\nif not HAS_IMPLICIT:\n    from sklearn.decomposition import TruncatedSVD as _TSVD2\n    print('implicit not available or failed; using TruncatedSVD fallback for MF factors')\n    svd_mf = _TSVD2(n_components=128, random_state=42)\n    als_item_factors_final = svd_mf.fit_transform(item_user_matrix_scale)\n    # user factors: approximate by dividing R^T * F by counts\n    try:\n        R = item_user_matrix_scale\n        user_num = (R.T).dot(als_item_factors_final)\n        user_counts = np.array((R != 0).sum(axis=0)).reshape(-1)\n        user_counts = np.where(user_counts == 0, 1.0, user_counts)\n        als_user_factors_final = (user_num / user_counts[:, None]).astype('float32')\n    except Exception:\n        als_user_factors_final = np.random.normal(scale=0.01, size=(n_users_scale, als_item_factors_final.shape[1])).astype('float32')\n\nsvd_item_factors_final = als_item_factors_final  # reuse\nitem_emb_norm_final = item_emb_final / (np.linalg.norm(item_emb_final, axis=1, keepdims=True) + 1e-9)\nprint('Final item_emb shape:', item_emb_final.shape)","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:27:57.544373Z","iopub.status.busy":"2025-09-28T17:27:57.543595Z","iopub.status.idle":"2025-09-28T17:50:28.236211Z","shell.execute_reply":"2025-09-28T17:50:28.235246Z"},"papermill":{"duration":1350.719042,"end_time":"2025-09-28T17:50:28.237610","exception":false,"start_time":"2025-09-28T17:27:57.518568","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-28 17:28:09.195444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1759080489.393914      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1759080489.452275      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df052f43814b434591ca16e3d73c7030","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01d4705909834307976baaa91e0c8548","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14380fa80ad643e0963a7da49320efce","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb5b478c1e3b4628a2abae43ac3b3fa0","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c0e2b132adc4a2fa072038a5b9506ca","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4edb8b738d84aa483d00381ab2dede9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c77b1e112bd4041be52f7062df95cbb","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f16956d634fe496c9d1e73b8229c42ec","version_major":2,"version_minor":0},"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"783237e1a603450982779ab660829cef","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d165961445fa4c7f8b4360f2b3e0be32","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad6d82f96d2746c5a1185b35dc44bfde","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c41f257a41c47c0acf0d557d26dffc9","version_major":2,"version_minor":0},"text/plain":["SBERT encode:   0%|          | 0/35 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 2 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n","  check_blas_config()\n","/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n","  check_blas_config()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3661426d80a740db9bdc0a5f1737b195","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final item_emb shape: (8907, 768)\n"]}],"execution_count":7},{"id":"9d7e8639","cell_type":"markdown","source":"## 6 — Scale Hard-negative Mining & Final LTR Training\n\nThis cell mines hard negatives across many users and trains the final LightGBM reranker on the large meta dataset.","metadata":{"papermill":{"duration":0.022869,"end_time":"2025-09-28T17:50:28.284291","exception":false,"start_time":"2025-09-28T17:50:28.261422","status":"completed"},"tags":[]}},{"id":"0e0ea100","cell_type":"markdown","source":"### Explanation for Cell 17\n\n**Purpose:** Imports libraries used later. Trains a model / fits parameters.\n\n**Line-by-line (short):**\n- `# Scale hard-neg mining + LTR training` → Comment describing intent.\n- `USERS_TO_USE_SCALE = 5000; HARD_NEG_PER_POS = 80; RANDOM_NEG_PER_POS = 5` → Performs a step relevant to data processing or modelling.\n- `meta_rows_scale = []` → Performs a step relevant to data processing or modelling.\n- `sample_users_scale = df_scale['reviewerID'].unique()[:min(USERS_TO_USE_SCALE, n_users_scale)]` → Performs a step relevant to data processing or modelling.\n- `for uid in tqdm(sample_users_scale, desc='Building Meta Scale'):` → Performs a step relevant to data processing or modelling.\n- `uidx = user_map_scale.get(uid);` → Performs a step relevant to data processing or modelling.\n- `if uidx is None: continue` → Performs a step relevant to data processing or modelling.\n- `cands = build_candidates_union(uidx, item_emb_final, (als_model_final if 'als_model_final' in globals() else None), svd_item_factors_final, item_map_scale, pop_counts_scale, user_map_scale, df_scale, interaction_scale, top_sem=1000, top_als=500, top_svd=500, top_pop=500, top_mf=200, max_cands=3000)` → Performs a step relevant to data processing or modelling.\n- `if not cands: continue` → Performs a step relevant to data processing or modelling.\n- `mf = build_features_for_candidates(uidx, cands, item_emb_final, (als_item_factors_final if 'als_item_factors_final' in globals() else None), (als_user_factors_final if 'als_user_factors_final' in globals() else None), svd_item_factors_final, df_scale, item_map_scale, user_map_scale, pop_counts_scale, feature_names, now_ts)` → Performs a step relevant to data processing or modelling.\n- `Xc = mf['X']; cidx = mf['cands']; fns = mf['feature_names']` → Performs a step relevant to data processing or modelling.\n- `true_asins = test_df_scale[test_df_scale['reviewerID']==uid]['asin'].tolist()` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"be3944ae","cell_type":"code","source":"# Scale hard-neg mining + LTR training\nUSERS_TO_USE_SCALE = 5000; HARD_NEG_PER_POS = 80; RANDOM_NEG_PER_POS = 5\nmeta_rows_scale = []\nsample_users_scale = df_scale['reviewerID'].unique()[:min(USERS_TO_USE_SCALE, n_users_scale)]\nfor uid in tqdm(sample_users_scale, desc='Building Meta Scale'):\n    uidx = user_map_scale.get(uid); \n    if uidx is None: continue\n    cands = build_candidates_union(uidx, item_emb_final, (als_model_final if 'als_model_final' in globals() else None), svd_item_factors_final, item_map_scale, pop_counts_scale, user_map_scale, df_scale, interaction_scale, top_sem=1000, top_als=500, top_svd=500, top_pop=500, top_mf=200, max_cands=3000)\n    if not cands: continue\n    mf = build_features_for_candidates(uidx, cands, item_emb_final, (als_item_factors_final if 'als_item_factors_final' in globals() else None), (als_user_factors_final if 'als_user_factors_final' in globals() else None), svd_item_factors_final, df_scale, item_map_scale, user_map_scale, pop_counts_scale, feature_names, now_ts)\n    Xc = mf['X']; cidx = mf['cands']; fns = mf['feature_names']\n    true_asins = test_df_scale[test_df_scale['reviewerID']==uid]['asin'].tolist()\n    true_idxs = [item_map_scale[a] for a in true_asins if a in item_map_scale]\n    if not true_idxs: continue\n    als_col = Xc[:, fns.index('als_score')] if 'als_score' in fns else np.zeros(Xc.shape[0])\n    svd_col = Xc[:, fns.index('svd_score')] if 'svd_score' in fns else np.zeros(Xc.shape[0])\n    hard_score = 0.5 * als_col + 0.5 * svd_col\n    cand_arr = np.array(cidx); pos_mask = np.isin(cand_arr, true_idxs); non_pos_idx = np.where(~pos_mask)[0]\n    if len(non_pos_idx)==0: continue\n    ordering = non_pos_idx[np.argsort(-hard_score[non_pos_idx])]; hard_negs_idx = ordering[:HARD_NEG_PER_POS].tolist()\n    remaining = list(set(non_pos_idx.tolist()) - set(hard_negs_idx)); random_negs_idx = random.sample(remaining, min(RANDOM_NEG_PER_POS, len(remaining))) if remaining else []\n    for t in true_idxs:\n        pos_loc = np.where(cand_arr==t)[0]; \n        if len(pos_loc)==0: continue\n        for p in pos_loc:\n            row = {'user_idx': uidx, 'item_idx': int(cidx[p]), 'label': 1}\n            for j,fn in enumerate(fns):\n                try: row[fn] = float(Xc[p,j])\n                except: row[fn] = 0.0\n            meta_rows_scale.append(row)\n            for idx in hard_negs_idx:\n                rn = {'user_idx': uidx, 'item_idx': int(cidx[idx]), 'label': 0}\n                for j,fn in enumerate(fns):\n                    try: rn[fn] = float(Xc[idx,j])\n                    except: rn[fn] = 0.0\n                meta_rows_scale.append(rn)\n            for idx in random_negs_idx:\n                rr = {'user_idx': uidx, 'item_idx': int(cidx[idx]), 'label': 0}\n                for j,fn in enumerate(fns):\n                    try: rr[fn] = float(Xc[idx,j])\n                    except: rr[fn] = 0.0\n                meta_rows_scale.append(rr)\nmeta_df_scale = pd.DataFrame(meta_rows_scale).sample(frac=1.0, random_state=42).reset_index(drop=True)\nprint('meta_df_scale shape:', meta_df_scale.shape)\n\n# Train final LTR\nfrom sklearn.model_selection import train_test_split\nfeat_cols = [c for c in meta_df_scale.columns if c not in ('user_idx','item_idx','label')]\nX = meta_df_scale[feat_cols].values; y = meta_df_scale['label'].values\nusers_all = meta_df_scale['user_idx'].unique(); train_u, valid_u = train_test_split(list(users_all), test_size=0.10, random_state=42)\ntr_mask = meta_df_scale['user_idx'].isin(train_u); val_mask = meta_df_scale['user_idx'].isin(valid_u)\nX_tr = meta_df_scale[tr_mask][feat_cols].values; y_tr = meta_df_scale[tr_mask]['label'].values; gr_tr = meta_df_scale[tr_mask].groupby('user_idx', sort=False).size().astype(int).values\nX_val = meta_df_scale[val_mask][feat_cols].values; y_val = meta_df_scale[val_mask]['label'].values; gr_val = meta_df_scale[val_mask].groupby('user_idx', sort=False).size().astype(int).values\n\ndtrain = lgb.Dataset(X_tr, label=y_tr, group=gr_tr); dval = lgb.Dataset(X_val, label=y_val, group=gr_val, reference=dtrain)\nparams_scale = {'objective':'lambdarank','metric':'ndcg','ndcg_eval_at':[10,50],'learning_rate':float(best_params_proto.get('learning_rate',0.05)),'num_leaves':int(best_params_proto.get('num_leaves',63)),'min_data_in_leaf':int(best_params_proto.get('min_data_in_leaf',20)),'feature_fraction':float(best_params_proto.get('feature_fraction',0.8)),'verbosity':-1,'seed':42,'feature_pre_filter':False}\nbst_final_scale = lgb.train(params_scale, dtrain, num_boost_round=1000, valid_sets=[dval], callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=100)])\njoblib.dump(bst_final_scale, f\"{OUT_DIR}/lgbm_reranker_final.joblib\")","metadata":{"execution":{"iopub.execute_input":"2025-09-28T17:50:28.333074Z","iopub.status.busy":"2025-09-28T17:50:28.332122Z","iopub.status.idle":"2025-09-28T18:44:48.440281Z","shell.execute_reply":"2025-09-28T18:44:48.439397Z"},"papermill":{"duration":3260.134033,"end_time":"2025-09-28T18:44:48.441579","exception":false,"start_time":"2025-09-28T17:50:28.307546","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7166bae877684f80853abc15f325c654","version_major":2,"version_minor":0},"text/plain":["Building Meta Scale:   0%|          | 0/1561 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["meta_df_scale shape: (129430, 16)\n","Training until validation scores don't improve for 50 rounds\n","[100]\tvalid_0's ndcg@10: 0.891412\tvalid_0's ndcg@50: 0.905366\n","Early stopping, best iteration is:\n","[65]\tvalid_0's ndcg@10: 0.893308\tvalid_0's ndcg@50: 0.906012\n"]},{"data":{"text/plain":["['/kaggle/working/lgbm_reranker_final.joblib']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"id":"24026924","cell_type":"markdown","source":"## 7 — Final Evaluation & Metrics\n\nCompute P@K, R@K, NDCG@K, MAP, and MPR for the LGBM hybrid reranker and a semantic baseline. Results are saved to `OUT_DIR/final_scale_summary_metrics.csv`.","metadata":{"papermill":{"duration":0.024157,"end_time":"2025-09-28T18:44:48.491027","exception":false,"start_time":"2025-09-28T18:44:48.466870","status":"completed"},"tags":[]}},{"id":"f85bdfaa","cell_type":"markdown","source":"### Explanation for Cell 19\n\n**Purpose:** Imports libraries used later. Defines function(s) used downstream. Produces predictions on data. Saves results or models to disk.\n\n**Line-by-line (short):**\n- `# Final evaluation utilities and run` → Comment describing intent.\n- `from math import log2` → Imports module(s).\n- `def ndcg_at_k(pred_list, true_list, k=10):` → Performs a step relevant to data processing or modelling.\n- `if not true_list: return 0.0` → Performs a step relevant to data processing or modelling.\n- `pred_k = pred_list[:k]; gains = [1.0 if p in true_list else 0.0 for p in pred_k]` → Performs a step relevant to data processing or modelling.\n- `dcg = sum(g / log2(i+2) for i,g in enumerate(gains)); idcg = sum(1.0 / log2(i+2) for i in range(min(len(true_list), k)))` → Performs a step relevant to data processing or modelling.\n- `return dcg/idcg if idcg>0 else 0.0` → Performs a step relevant to data processing or modelling.\n- `def apk(actual, predicted, k=10):` → Performs a step relevant to data processing or modelling.\n- `if not actual: return 0.0` → Performs a step relevant to data processing or modelling.\n- `score = 0.0; num_hits = 0.0` → Performs a step relevant to data processing or modelling.\n- `for i,p in enumerate(predicted[:k]):` → Performs a step relevant to data processing or modelling.\n- `if p in actual and p not in predicted[:i]:` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"a00fd376","cell_type":"code","source":"# Final evaluation utilities and run\nfrom math import log2\ndef ndcg_at_k(pred_list, true_list, k=10):\n    if not true_list: return 0.0\n    pred_k = pred_list[:k]; gains = [1.0 if p in true_list else 0.0 for p in pred_k]\n    dcg = sum(g / log2(i+2) for i,g in enumerate(gains)); idcg = sum(1.0 / log2(i+2) for i in range(min(len(true_list), k)))\n    return dcg/idcg if idcg>0 else 0.0\n\ndef apk(actual, predicted, k=10):\n    if not actual: return 0.0\n    score = 0.0; num_hits = 0.0\n    for i,p in enumerate(predicted[:k]):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0; score += num_hits/(i+1.0)\n    return score/min(len(actual), k)\n\ndef lgbm_final_topk(uidx, k=10):\n    cands = build_candidates_union(uidx, item_emb_final, (als_model_final if 'als_model_final' in globals() else None), svd_item_factors_final, item_map_scale, pop_counts_scale, user_map_scale, df_scale, interaction_scale, top_sem=1000, top_als=500, top_svd=500, top_pop=500, top_mf=200, max_cands=3000)\n    if not cands: return []\n    mf = build_features_for_candidates(uidx, cands, item_emb_final, (als_item_factors_final if 'als_item_factors_final' in globals() else None), (als_user_factors_final if 'als_user_factors_final' in globals() else None), svd_item_factors_final, df_scale, item_map_scale, user_map_scale, pop_counts_scale, feature_names, now_ts)\n    preds = bst_final_scale.predict(mf['X']); order = np.argsort(-preds)[:k]; return [cands[i] for i in order]\n\ndef semantic_final_topk(uidx, k=10):\n    uvec = user_profile_emb(uidx, item_emb_final, df_scale, item_map_scale, user_map_scale); uvec = uvec/(np.linalg.norm(uvec)+1e-9)\n    scores = item_emb_final.dot(uvec); return list(np.argsort(-scores)[:k])\n\ndef evaluate_final(scorer_fn, K=10, max_users=1000):\n    actuals=[]; preds=[]; cnt=0\n    for uid in tqdm(test_df_scale['reviewerID'].unique()[:max_users], desc=f\"Evaluating {scorer_fn.__name__}\"):\n        if uid not in user_map_scale: continue\n        uidx = user_map_scale[uid]\n        true_asins = test_df_scale[test_df_scale['reviewerID']==uid]['asin'].tolist()\n        if not true_asins: continue\n        rec_idxs = scorer_fn(uidx, k=K)\n        rec_asins = [inv_item_map_scale[i] for i in rec_idxs if i in inv_item_map_scale]\n        preds.append(rec_asins); actuals.append(true_asins); cnt += 1\n    if cnt==0: return {'P@10':0.0,'R@10':0.0,'NDCG@10':0.0,'MAP@10':0.0,'MPR@10':0.0,'EvalUsers':0}\n    P = np.mean([len(set(p[:K]) & set(a))/float(K) for p,a in zip(preds,actuals)])\n    R = np.mean([len(set(p[:K]) & set(a))/max(1,len(a)) for p,a in zip(preds,actuals)])\n    N = np.mean([ndcg_at_k(p,a,K) for p,a in zip(preds,actuals)])\n    MAP = np.mean([apk(a,p,K) for a,p in zip(actuals,preds)])\n    MPR = np.mean([np.mean([1.0 - (p.index(t)+1)/K if (t in p[:K]) else 0.0 for t in a]) for a,p in zip(actuals,preds)])\n    return {'P@10':P,'R@10':R,'NDCG@10':N,'MAP@10':MAP,'MPR@10':MPR,'EvalUsers':len(actuals)}\n\nfinal_results = {}\nfinal_results['LGBM_Hybrid_Rerank'] = evaluate_final(lgbm_final_topk, K=10)\nfinal_results['Semantic_Baseline'] = evaluate_final(semantic_final_topk, K=10)\nfinal_df = pd.DataFrame(final_results).T\nfinal_df = final_df[['P@10','R@10','NDCG@10','MAP@10','MPR@10','EvalUsers']]\nfinal_df.to_csv(f\"{OUT_DIR}/final_scale_summary_metrics.csv\", index=False)\nprint('Final evaluation complete — metrics saved to', f\"{OUT_DIR}/final_scale_summary_metrics.csv\")","metadata":{"execution":{"iopub.execute_input":"2025-09-28T18:44:48.539093Z","iopub.status.busy":"2025-09-28T18:44:48.538468Z","iopub.status.idle":"2025-09-28T19:20:54.374171Z","shell.execute_reply":"2025-09-28T19:20:54.373263Z"},"papermill":{"duration":2165.861129,"end_time":"2025-09-28T19:20:54.375460","exception":false,"start_time":"2025-09-28T18:44:48.514331","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc7974c9d2b94c07a3910a63c216ff4c","version_major":2,"version_minor":0},"text/plain":["Evaluating lgbm_final_topk:   0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"711fcdd4e28e4c8aa20386e0fbb16c8a","version_major":2,"version_minor":0},"text/plain":["Evaluating semantic_final_topk:   0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final evaluation complete — metrics saved to /kaggle/working/final_scale_summary_metrics.csv\n"]}],"execution_count":9},{"id":"513972a0","cell_type":"markdown","source":"### Feature importance\n\nExport and inspect feature importances from the final LightGBM model.","metadata":{"papermill":{"duration":0.02537,"end_time":"2025-09-28T19:20:54.427425","exception":false,"start_time":"2025-09-28T19:20:54.402055","status":"completed"},"tags":[]}},{"id":"ac316c2f","cell_type":"markdown","source":"### Explanation for Cell 21\n\n**Purpose:** Saves results or models to disk.\n\n**Line-by-line (short):**\n- `# Feature importances` → Comment describing intent.\n- `fi_df = pd.DataFrame({'feature': feat_cols, 'importance': bst_final_scale.feature_importance()}).sort_values('importance', ascending=False)` → Performs a step relevant to data processing or modelling.\n- `fi_df.to_csv(f\"{OUT_DIR}/feature_importances_final.csv\", index=False)` → Performs a step relevant to data processing or modelling.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"dcc62430","cell_type":"code","source":"# Feature importances\nfi_df = pd.DataFrame({'feature': feat_cols, 'importance': bst_final_scale.feature_importance()}).sort_values('importance', ascending=False)\nfi_df.to_csv(f\"{OUT_DIR}/feature_importances_final.csv\", index=False)","metadata":{"execution":{"iopub.execute_input":"2025-09-28T19:20:54.475713Z","iopub.status.busy":"2025-09-28T19:20:54.474999Z","iopub.status.idle":"2025-09-28T19:20:54.482988Z","shell.execute_reply":"2025-09-28T19:20:54.482204Z"},"papermill":{"duration":0.033132,"end_time":"2025-09-28T19:20:54.484266","exception":false,"start_time":"2025-09-28T19:20:54.451134","status":"completed"},"tags":[]},"outputs":[],"execution_count":10},{"id":"8f5df73d","cell_type":"markdown","source":"### Explanation for Cell 22\n\n**Purpose:** Performs an operation relevant to the pipeline (see code).\n\n**Line-by-line (short):**\n- `# Fixed sample recommendation printing (maps indices -> ASIN strings, computes true HITs)` → Comment describing intent.\n- `SAMPLE_USERS_TO_DISPLAY = 5` → Performs a step relevant to data processing or modelling.\n- `test_users = test_df_scale['reviewerID'].unique()` → Performs a step relevant to data processing or modelling.\n- `if len(test_users) == 0:` → Performs a step relevant to data processing or modelling.\n- `print(\"\\nNo unique test users found to display sample recommendations.\")` → Displays a quick diagnostic for the user.\n- `else:` → Performs a step relevant to data processing or modelling.\n- `num_samples = min(SAMPLE_USERS_TO_DISPLAY, len(test_users))` → Performs a step relevant to data processing or modelling.\n- `sample_uids = random.sample(list(test_users), num_samples)` → Samples rows from a DataFrame.\n- `print(f\"\\n--- Sample User Recommendation Output (LGBM Hybrid) for {num_samples} Users ---\")` → Displays a quick diagnostic for the user.\n- `for sample_uid in sample_uids:` → Performs a step relevant to data processing or modelling.\n- `sample_uidx = user_map_scale.get(sample_uid)` → Performs a step relevant to data processing or modelling.\n- `if sample_uidx is None:` → Performs a step relevant to data processing or modelling.\n\n...remaining lines omitted for brevity. See code cell for full content.\n\n**Inputs:** likely dataframes, parameters, and previously defined variables.\n**Outputs:** new variables in memory (dataframes, models, figures), possibly files on disk.\n\n**Notes:** Verify paths, column names, and variable names. Consider adding assertions to safeguard assumptions.\n","metadata":{}},{"id":"0c22cd72","cell_type":"code","source":"\n# Fixed sample recommendation printing (maps indices -> ASIN strings, computes true HITs)\nSAMPLE_USERS_TO_DISPLAY = 5\n\ntest_users = test_df_scale['reviewerID'].unique()\nif len(test_users) == 0:\n    print(\"\\nNo unique test users found to display sample recommendations.\")\nelse:\n    num_samples = min(SAMPLE_USERS_TO_DISPLAY, len(test_users))\n    sample_uids = random.sample(list(test_users), num_samples)\n\n    print(f\"\\n--- Sample User Recommendation Output (LGBM Hybrid) for {num_samples} Users ---\")\n\n    for sample_uid in sample_uids:\n        sample_uidx = user_map_scale.get(sample_uid)\n\n        if sample_uidx is None:\n            print(f\"\\n[SKIP] User {sample_uid} not in user_map_scale.\")\n            continue\n\n        if 'bst_final_scale' not in globals() or bst_final_scale is None:\n            print(\"\\n[SKIP] bst_final_scale not available — model wasn't trained or loaded.\")\n            break\n\n        # true ASIN string\n        actual_asin = test_df_scale[test_df_scale['reviewerID'] == sample_uid]['asin'].iloc[0]\n\n        # get recommended item indices (ints)\n        rec_idxs = lgbm_final_topk(sample_uidx, k=10)\n\n        # convert indices -> ASINs (use appropriate inv map)\n        inv_map = inv_item_map_scale if 'inv_item_map_scale' in globals() else inv_item_map\n        rec_asins = [inv_map[i] if (i in inv_map) else f\"IDX_{i}\" for i in rec_idxs]\n\n        print(f\"\\nUser ID: {sample_uid}\")\n        print(f\"True Last Item (to predict): {actual_asin}\")\n        print(\"Top 10 Recommended ASINs:\")\n        for i, asin in enumerate(rec_asins):\n            hit_status = \"✅ HIT\" if asin == actual_asin else \"❌ MISS\"\n            print(f\"  {i+1}. {asin} ({hit_status})\")\n\n        # helpful additional info: was the true item present in the candidate set at all?\n        # Build candidate set with the same function used by the scorer (using larger pool for clarity)\n        cands = build_candidates_union(sample_uidx,\n                                       item_emb_final if 'item_emb_final' in globals() else None,\n                                       als_model_final if 'als_model_final' in globals() else None,\n                                       svd_item_factors_final if 'svd_item_factors_final' in globals() else None,\n                                       item_map_scale if 'item_map_scale' in globals() else item_map,\n                                       pop_counts_scale if 'pop_counts_scale' in globals() else pop_counts,\n                                       user_map_scale if 'user_map_scale' in globals() else user_map,\n                                       df_scale if 'df_scale' in globals() else df,\n                                       interaction_scale if 'interaction_scale' in globals() else interaction,\n                                       top_sem=1000, top_als=500, top_svd=500, top_pop=500, top_mf=200, max_cands=3000)\n        cand_asins = {inv_map[i] for i in cands if i in inv_map}\n        in_candidates = actual_asin in cand_asins\n        print(f\"True ASIN in candidate pool? {'YES' if in_candidates else 'NO'}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-09-28T19:20:54.532505Z","iopub.status.busy":"2025-09-28T19:20:54.531877Z","iopub.status.idle":"2025-09-28T19:21:05.468478Z","shell.execute_reply":"2025-09-28T19:21:05.467401Z"},"papermill":{"duration":10.961829,"end_time":"2025-09-28T19:21:05.469690","exception":false,"start_time":"2025-09-28T19:20:54.507861","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Sample User Recommendation Output (LGBM Hybrid) for 5 Users ---\n","\n","User ID: AEN2ZU26WIC33EXP6LTYOWMV36XQ\n","True Last Item (to predict): B07CKV9FRX\n","Top 10 Recommended ASINs:\n","  1. B07CKV9FRX (✅ HIT)\n","  2. B06Y5RTN1T (❌ MISS)\n","  3. B002IVVDFU (❌ MISS)\n","  4. B0791TX5P5 (❌ MISS)\n","  5. B079QHML21 (❌ MISS)\n","  6. B00ZVJAF9G (❌ MISS)\n","  7. B00U3FPN4U (❌ MISS)\n","  8. B00OQVZDJM (❌ MISS)\n","  9. B0051VVOB2 (❌ MISS)\n","  10. B00N2ZDXW2 (❌ MISS)\n","True ASIN in candidate pool? YES\n","\n","User ID: AHWFJZKOUI2EMNQSPHDDDSMOOF4A\n","True Last Item (to predict): B009AOGJDE\n","Top 10 Recommended ASINs:\n","  1. B009AOGJDE (✅ HIT)\n","  2. B00LSD51I4 (❌ MISS)\n","  3. B00ZTRYG3Q (❌ MISS)\n","  4. B089F9YDFC (❌ MISS)\n","  5. B00OQVZDJM (❌ MISS)\n","  6. B07T25WP4N (❌ MISS)\n","  7. B009S2CXLK (❌ MISS)\n","  8. B01AFQQBCY (❌ MISS)\n","  9. B07RV6NRQN (❌ MISS)\n","  10. B078XRNNDG (❌ MISS)\n","True ASIN in candidate pool? YES\n","\n","User ID: AFMOHJOF54QARPV5DJNPJDN3F4AQ\n","True Last Item (to predict): B083RXCTRQ\n","Top 10 Recommended ASINs:\n","  1. B083RXCTRQ (✅ HIT)\n","  2. B07SB3MN9N (❌ MISS)\n","  3. B0BL7HNSZW (❌ MISS)\n","  4. B07M6BXRML (❌ MISS)\n","  5. B0791TX5P5 (❌ MISS)\n","  6. B07RB54XJ2 (❌ MISS)\n","  7. B006GWO5WK (❌ MISS)\n","  8. B07YNLBS7R (❌ MISS)\n","  9. B00BWF5U0M (❌ MISS)\n","  10. B01M334NVP (❌ MISS)\n","True ASIN in candidate pool? YES\n","\n","User ID: AHNAOQRKXEQI7U7FBGHAWLZGHECQ\n","True Last Item (to predict): B00KC0HVTQ\n","Top 10 Recommended ASINs:\n","  1. B0043T7FXE (❌ MISS)\n","  2. B003I4FF28 (❌ MISS)\n","  3. B07TTSPWMB (❌ MISS)\n","  4. B07H8TJMX7 (❌ MISS)\n","  5. B00QRPPCMI (❌ MISS)\n","  6. B015TJD0Y4 (❌ MISS)\n","  7. B01MZEEFNX (❌ MISS)\n","  8. B07FZ8S74R (❌ MISS)\n","  9. B0791TX5P5 (❌ MISS)\n","  10. B00ZV9RDKK (❌ MISS)\n","True ASIN in candidate pool? YES\n","\n","User ID: AHUZNBF5YKIQB7DWRVD7UKJ7ZMUQ\n","True Last Item (to predict): B07WTBC2KS\n","Top 10 Recommended ASINs:\n","  1. B07WTBC2KS (✅ HIT)\n","  2. B06ZZGPD4D (❌ MISS)\n","  3. B07YYB1NSR (❌ MISS)\n","  4. B007FG43R8 (❌ MISS)\n","  5. B015NBTAOW (❌ MISS)\n","  6. B089F9YDFC (❌ MISS)\n","  7. B00OQVZDJM (❌ MISS)\n","  8. B07HMRZMTM (❌ MISS)\n","  9. B01LY0G6UP (❌ MISS)\n","  10. B085FDQYFX (❌ MISS)\n","True ASIN in candidate pool? YES\n"]}],"execution_count":11},{"id":"c0429d61","cell_type":"markdown","source":"## 8 — Diagnostics, Ablations & Next Steps\n\n**Diagnostics included in this notebook:**\n\n- Candidate recall checks (small and large pools)\n- Feature distributions for positives vs negatives\n- Per-user inspection utilities (`inspect_user_rerank`, `compare_top_bottom`)\n\n**Suggested next steps:**\n\n1. If reranker underperforms but recall is high: increase meta training size, upsample positives, and tune hard-negative ratios.\n2. If ALS/SVD features are weak, consider training implicit ALS on denser data or using matrix factorization with alternating optimization.\n3. Add more content features (title tokens, brand, category) and context signals (time of day, device) if available.\n4. For production: build offline candidate pipeline (FAISS HNSW) and a lightweight online reranker (optimized model export).\n\n---\n\nEnd of notebook. All cells are code or markdown only; no outputs were saved here. Run sequentially in a reproducible environment and adjust hyperparameters as needed.","metadata":{"papermill":{"duration":0.024086,"end_time":"2025-09-28T19:21:05.518499","exception":false,"start_time":"2025-09-28T19:21:05.494413","status":"completed"},"tags":[]}},{"id":"1f595536","cell_type":"code","source":"\n# Final evaluation metrics table (prints available metrics if present in the notebook's namespace)\nfrom IPython.display import display\nimport pandas as pd\nimport numpy as np\nmetrics_rows = []\ntry:\n    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n    sklearn_available = True\nexcept Exception:\n    sklearn_available = False\n\npossible_truth = ['y_true', 'y_test', 'test_labels', 'y_actual']\npossible_pred = ['y_pred', 'predictions', 'yhat']\npossible_score = ['y_score', 'y_proba', 'probabilities']\n\ndef find_var(varnames, g=globals()):\n    for n in varnames:\n        if n in g:\n            return n,g[n]\n    return None, None\n\ny_name, y_true = find_var(possible_truth)\nyp_name, y_pred = find_var(possible_pred)\nys_name, y_score = find_var(possible_score)\n\nif y_true is not None and y_pred is not None and sklearn_available:\n    try:\n        acc = accuracy_score(y_true, y_pred)\n        prec = precision_score(y_true, y_pred, average='binary' if len(np.unique(y_true))==2 else 'macro', zero_division=0)\n        rec = recall_score(y_true, y_pred, average='binary' if len(np.unique(y_true))==2 else 'macro', zero_division=0)\n        f1 = f1_score(y_true, y_pred, average='binary' if len(np.unique(y_true))==2 else 'macro', zero_division=0)\n        df = pd.DataFrame({'metric':['accuracy','precision','recall','f1'], 'value':[acc, prec, rec, f1]}).set_index('metric')\n        display(df)\n    except Exception as e:\n        print('Could not compute standard metrics automatically:', e)\n    if y_score is not None:\n        try:\n            auc = roc_auc_score(y_true, y_score)\n            display(pd.DataFrame({'metric':['roc_auc'],'value':[auc]}).set_index('metric'))\n        except Exception as e:\n            print('Could not compute ROC-AUC:', e)\nelse:\n    template = pd.DataFrame({\n        'metric': ['accuracy','precision','recall','f1','roc_auc (if available)'],\n        'value': ['<compute with sklearn.metrics...>']*5,\n        'interpretation': [\n            'Proportion of correct predictions (higher is better; baseline depends on class balance).',\n            'Precision: proportion of predicted positives that are correct. High precision = few false positives.',\n            'Recall: proportion of actual positives that were found. High recall = few false negatives.',\n            'F1: harmonic mean of precision and recall — balances both.',\n            'Area under ROC curve (probabilistic): 1.0 is perfect, 0.5 is random guessing.'\n        ]\n    }).set_index('metric')\n    display(template)\n    print('\\nGuidance: If your notebook defines y_test and y_pred (or similar names), run the whole notebook then re-run this cell to compute real metrics.')\n","metadata":{},"outputs":[],"execution_count":null}]}